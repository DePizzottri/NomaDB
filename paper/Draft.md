### Абстракт.

Изучаем минимальные по потреблению памяти способы отслеживания причинности для реплицированных данных в распределенных системах.
Изучаем схемы синхронизаций, образующие посеты размерности 2.
    
## Описание проблемы, актулаизация.

С кардинальным ростом нагрузок на хранилища данных (требование к обработке больших количеств запросов на запись и чтение) возникает потребность перехода на парадигмы в области архитектуры СУБД, отличные от центральный сервер - клиенты. 
[Amazon Dynamo](https://aws.amazon.com/dynamodb/), [Cassandra](http://cassandra.apache.org/) и [Riak KV](http://basho.com/products/riak-kv/) являются яркими представителями таких СУБД, архитектура которых сосредоточенна на _усточивости к разделению_, _доступности для чтения/записи_ и _согласованности в конечном итоге_. 

Подобные распределенные системы лежат в области действия эвристической теоремы [CAP](https://en.wikipedia.org/wiki/CAP_theorem)[1], утверждающей что среди требований _согласованности_ (1), _доступности_(2) и  _устойчивости к разделению_ (3) одновременно можно достич только 2х.

Кроме того, возникают дополнительные требования, в виде массовой репликации - для достижения распределения нагрузки, децентрализации и большему повышению доступности и гео-распределенности - системы хранения данных становятся глобальными.
Принимая во внимание дополнительные требования неизбежным является ослабление ограничений _согласованности_ - со строгой согласованности до [согласованности в конечном итоге](https://en.wikipedia.org/wiki/Eventual_consistency) [2][3].

Подобные системы следуют дизайну, где данные всегда могут быть записанны: копиям (репликам) одних и тех-же данных на разных узлах позволено быть частично отличными. Однако в зависимотсти от способа синхронизаций могут происходить конфликты, наподобии возникновения нескольких конкуррентных копий либо потерянных обновлений данных. 
    **Пример кассандры**
    **Пример динамо**

Для поддержания полной согласованности и возможности синхронизаций копий используются различные механизмы отслеживания причинно-следственных зависимостей в данных. Наиболее распространенный и известный - [version vector](https://en.wikipedia.org/wiki/Version_vector) [4][5], однако линейно зависит по памяти от количества реплик, а потому не ожет быть эффективно использован в системах с массовой репликацией.

За последнее время создано немало альтернатив, одни из которых являются вариацией на тему вектора версий, другие же используют принципиально иной подход.
Среди них можно выделить:

* [Dotted Version Vector](http://gsd.di.uminho.pt/members/vff/dotted-version-vectors-2012.pdf)[6]. Пожалуй наиболее практичный из всех. Основывается на принципе выделения специального подмножества (серверных) узлов, которые непосредственно отслеживают причинностную информацию; и на концепции точек (dots), призванную отличать пропуски в обновлениях, совершенных на не "серверных узлах". Уменьшая требуемый объем памяти, использование DVV делает систему неполноценно p2p, а точки пораждают необходимость хранить полые данные для этих точек.
    
* [Hash Histories](http://oceanstore.cs.berkeley.edu/publications/papers/pdf/hh_icdcs03_kang.pdf)[7]. Полностью хранит посет исполнения (см. ниже) в виде графа с узлами, содержащими хэш от данных. С одной стороны содержит избыточную информацию, с другой - имеет возможность обнаружения одинаковых копий, которое не следует из причинных связей.
    
* [Version stamps](http://haslab.uminho.pt/cbm/files/10.1.1.16.8235.pdf)[8]. Основывается на принципе динамичекого выведения идентификаторов для узлов, которое одновременно служит и способом отличать параллельные событи от зависимых. Объем дополнительных данных линейно зависит от количества обновлений и синхронизаций.
    
* Эти способы относятся к классу _точных_ - т.е. в любом случае корректно определяют причинностные отношения между двумя копиями.
    
* Также существуют неточные - для которых не всегда можно утверждать (либо утверждать с вероятностью < 1) паралелльны ли данные или находятся в причинно-следственной связи. И способы, полагающиеся на определенную топологию сети.

Важно также отметить связь между отслеживанием причинности и логическиеми часами. Первое можно рассматривать как частный случай логических часов, потому в определенной степени варианты таких часов могут быть рассмотрены в настоящем контексте [статья](https://haslab.wordpress.com/2011/07/08/version-vectors-are-not-vector-clocks/) [9]. Об этой связи подробнее ниже **[?]**.

Кроме всего прочего, отслеживание информации о причинностных связях используют в других областях знаний, в частности социологии и исследовании социальных сетей [статья](https://arxiv.org/pdf/1304.4058.pdf)[10] и недостатки, в частности version vector, проявляются там особенно остро.

## CRDT

Основываясь на опыте распределенных баз данных с master-master репликацией и обобщая способы согласования данных в системах с нестрогим согласованием данных были выведены Безконфликтные Реплицируемые Структуры Данных (англ. CRDT - Conflict Free Replicated Data Types). Использование таких структур гарантируют _строгую_ согласованность в конечном итоге [3]. Кроме прочего CRDT в явном виде уже использует, или собираются вводить множество крупных собременных СУБД: **MS[ссылка], Redis[ссылка], [ссылка с тех слайдов]**

Существуют два типа CRDT [[23]](https://hal.inria.fr/inria-00555588/document): 
* CvRDT - ориентированный на операции (коммутативные, op-based CRDT,  Commmutative RDT). В которых репликация осуществляется атомарным распространением операций модификации. Такие операции должны быть коммутативными для того, чтобы структура данных сходилась к единому стостоянию
* СmRDT - ориентированные на состояния (конвергентные (сходящиеся), state-based CRDT, Convergent RDT). В которых репликация осуществляется распространением состояния, которые в свою очередь сливаются воедино при помощи операции merge. Существует модификация δ-CRDT, в которых репликация производится слиянием не полного состояния, а лишь измененной части.

В свою очередь каждая из радновидностей отличается приемуществами и недостатками:
+ CvRDT
	+ **+** низкое потребление траффика при распростанениий операций
	+ **-** требуется атомарный широковещательный способ распространения операций
	+ **-** причинностный порядок распростарнения операций
	**(УТОЧНИТЬ ТУТ ПРО VV в OP-CRDT)**
+ δ-CmRDT
	+ **+** раcпростарнение состояния при помощи алгоритмов распростарнения слухов
	+ **-** дополнительная метаинформация для отслеживания причинно-следственной связи.
	+ **-** потребление траффика выше, чем у CvRDT

Основной задачей, стоящей перед δ-CmRDT на данный момент является минимизация возможного траффика. Часть решения этой задачи заключается в уменшении количества повторных пересылок частей данных, что отчасти решается в работе [[24]](http://haslab.uminho.pt/cbm/files/pmldc-2016-join-decomposition.pdf). Другая часть заключается в уменьшении объема непосредственно пересылаемых данных и метаданных.

Несмотря на свою универсальность оба вида CRDT пока плохо подходят для _массовой репликации_, такой, при которой количество реплик составляет порядка сотен тысяч и даже миллионов. В случае δ-CmRDT существенню роль играет метаинформация, отслеживающая причинно - следственные связи, которая как правило по потребляемым ресурсам памяти зависит как O(N), где N - количество реплик.

Таким образом нахождение "дешевых" механизмов отслеживания причинно-следственных связей, 
при применений их в качестве метаинформации (кроме других общих случаевх их применения) в CRDT позволяет существенно оптимизировать потребляемые ресурсы при синхронизации.

Данная работа ставит целью изучение возможности и способов понизить накладные расходы по памяти при отслеживании причинностных связей при сохранении точности, а также выведения практически применимых схем построения метаинформации. Учитывая известные оценки сложности[11] (подробнее в главе Х) описывается и анализируется определенный класс моделей.

Исследуя синхронизирующиеся процессы в модели Лэмпорта [[12]](https://amturing.acm.org/p558-lamport.pdf), описанные в главе Х, обнаруживается возможность сведения задачи к рассмотрению некоторого набора параметризированных конфигураций синхронизирующихся процессов (главы Х и Y). Варьируя параметр отвечающий за количество процессов выведенны некотроые свйоства для N = 3, 4, 5 и 6 (глава X). Основываясь на полученных результатах предпринята попытка вывести схему постноения метаинформации (глава X)
   
## Краткое описание схемы статьи.

Темы статей по материалу (по степени важности/уменьшения объема):

1. Вывод оптимального алгоритма антиэнтропии для CRDT. Оптимальность заключается в минимизации накладных расходов на поддержание метаинформации. Отслеживаем причинностную информацию посетами минимальной размерности.

2. Генерация синхронизирующихся процессов размерности 2. 
        Описать сведение задачи, алгоритм генерации и спосоы композиции.
        
3. Алгоритм проверки посета на размерность == 2
    
4. Изоморфизм посетов синхронизирующихся процессов.

## Понятия и определения.

Приведем необходимые в дальнейшем понятия, определения и теоремы.

Множество P, c заданным на нем бинарном отношение , обладающее свойствами рефлексивности и транзитивности называется _предпорядком_.

**Частично упорядоченное множество** (ЧУМ, посет (от англ. partially ordered set - poset)): множество P с введенным на нем бинарным отношением ≤, удовлетворяющим аксиомам рефлексивности, антисимметричности и транзитивности. Формально, для любых a, b и c принадлежащим P должно выполнятся.

В статье для краткости используется калька с английского - **посет** (poset) - в качестве альтернативы ЧУМ.

1. a ≤ a (рефлексивность - каждый элемент сравним сам с собой)
2. если a ≤ b и b ≤ a, то a=b (антисимметричность - два различных элемента не могут быть сравнимы только с одной стороны)
3. если a ≤ b и b ≤ c, тогда a ≤ c(два элемента сравнимы через третий транзитивно)
    
Самое отношение ≤ называют отношением частичного порядка.

Для удобства в рамках данной статьи для обозначения частичного порядка будем использовать символ →.

Для любых двух элементов а и b ∈ (P, →) если a→b или b→a, то говорят что а и b сравнимы, иначе a и b несравнимы.

**Линейно (тотально) упорядоченное множество** - это посет, в котором любые два элемента сравнимы.
Такой посет также называют цепью. В свою очередь посет, в котором любые два элемента попарно несравнимы называют антицепью.

**Линейное расширение** (продолжение) - для посета (P, →) это такой линейний порядок (L, →), для которого выполняется:
    
1. L = P, базовые множества совпадают
2. если a→b в посете, то a→b в линейном порядке. линейное расширение сохраняет порядок посета.

**Теорема (_Шпильрайн_)**:
    Для любого посета существет линейное расширение [[13]](https://en.wikipedia.org/wiki/Szpilrajn_extension_theorem).
    
**Ширина посета** - это количество элементов в максимальной антицепи. Формально:
    X ∈ P | X - антицепь, для любого Y ∈ P, Y - антицепь |X|>=|Y|,
    |X| - и есть ширина

**Теорема (_Дилворт_)**:
    Минимальное количество цепей, на которое можно разбить посет равно количеству элементов в максимально антицепи [[14]](https://en.wikipedia.org/wiki/Dilworth%27s_theorem).
    
Отсюда второе определение ширины:

Ширина посета - минимальное количество цепей, на которое можно разбить посет
    
**Высота посета** - количество элементов в наидлиннейшей цепи. Формально
    X ∈ P | X - цепь, для любого Y ∈ P, Y - цепь |X|>=|Y|,
    |X| - есть длина
    
**Реалайзер** - для посета (P, →) набор линейных расширений, пересечение которых дает исходный посет P.

**Размерность посета** (P, →) - это риалайзер минимального размера.

Размерность принято обозначать **dim(P)** [[15]](http://www.jstor.org/stable/2371374)

**Теорема (_Хирагучи_)**:
    Размерность посета P не превосходит его ширины [16].

**Критическая парa** элементов (a, b), это такая упорядоченная пара несравнимых элементов посета P, которые

* несравнимы
* для любого z ∈ P, из того что b→z, следует что a→z
* для любого z ∈ P, из того что z→a, следует что z→b
    
Следствие: если (a, b) критическая пара, то добавление отношения a→b к P остается частичным порядком, т.е. не нарушает требование транзитивности.

Линейное расширение L _реверсирует_ критическую пару (a, b) если для L верно что b→a.

Набор линейных расширений тогда будет являться риалайзером, когда каждая критическая пара будт обращена хотябы в одном из них.

По поводу вычисления размерности произвольного посета можно сказать следующее:

**Утверждение (_Янакаккис_)** Задача определения того, что посет имеет размерность больше 2х является NP-полной [[17]](https://www.researchgate.net/publication/230596220_The_Complexity_of_the_Partial_Order_Dimension_Problem).
Как следствие, для проверки того что посет имеет размерность меньше трех существет полиномиальный алгоритм.

**Гиперграф несовместных пар H(P)** это такой гиперграф, в котором вершинами явлются несравнимые пары элементов P, а гиперребра строятся на тех множествах S несравнимых пар, для которых выполняется:
    
* Ниодно линейное расширение не реверсирует одновременно все элементы S.
* Если T собственное подмножество S, то существует линейное расширение P, которое реверсирует все несравнимые пары.

Таки образом гиперребрами будут  те минимальне наборы несравнимых пар, которые нельзя одновременно обратить в одном линейном расширении.

**Графом несовместных пар G(P)** будет назваться пограф H(P) с ребрами размера 2.

**Гиперграф несовместных критических пар H<sub>c</sub>(P)** это подграф H(P), в котором оставлены только вершины - критические пары.

Аналогично **граф несовместных критических пар G<sub>c</sub>(P)** это подграф G(P), построенный только на критических парах.

**Хроматическое число χ(H)** (гипер)графа H - это минимальное число k, такое что множество вершин графа можно разбить на k непересекающихся классов.

Для (гипер)графов несовместных и критических пар верны следующие неравенства:
    dim(P) == χ(H) == χ(H<sub>c</sub>) >= χ(G) == χ(G<sub>c</sub>)    
   
**Теорема (Фелснер, Троттер)**:
    Если граф G<sub>c</sub>(P) это граф несовместных критических пар посета P, который не является линейным порядком. Тогда размерность посета P будет равна 2 если, и только если χ(G) == 2 [[18]](https://link.springer.com/article/10.1023/A:1006429830221).

## Моделирование посетов.

Системная модель.

В основе лежит классическа асинхронная распеределенная система, модель, состоящая из N распределенных процессов P<sub>1</sub> ...P<sub>N</sub>. Процессы не разделяют общие ресуры и сообщаются между собой путем парной передачи сообщений по сети, имеющей произвольную топологию. Коммуникация является асинхронной, с произвольно долгой, но предсказуемой задержкой. Важно что процессы не имеют доступа к глобальным часам и могут использованны только локальные часы.

Понятие времени в таких системах определяется тем, связанны ли события причинно-следственныи связями следующим образом:
    
1. Если два различных события е<sub>1</sub> и е<sub>2</sub> произошли в рамках одного процесса, и е<sub>1</sub> наступило раньше е<sub>2</sub>, то е<sub>1</sub> предшествует е<sub>2</sub>  (е<sub>1</sub> → e<sub>2</sub>).
2. Если е<sub>1</sub> это событие отправки сообщения, а е<sub>2</sub> событие получения, то е<sub>1</sub> предшествует е<sub>2</sub> (е<sub>1</sub> → e<sub>2</sub>).
3. Если е<sub>1</sub>, е<sub>2</sub> и е<sub>3</sub> различные события, (е<sub>1</sub> → e<sub>2</sub>) и (е<sub>2</sub> → e<sub>3</sub>), то е<sub>1</sub> предшествует е<sub>3</sub> (e<sub>1</sub> → e<sub>3</sub>).
    
Таким образом для событий распределенной системы вводится отношение частичного порядка →, которое отражает причинно следственные связи между ними. События, не связанные между собой отношением предшествования → быдем называть паралелльными e<sub>1</sub> || e<sub>2</sub>. Эту модель ввел Лесли Лэмпорт, под названием произошло до (англ. happens before) [12].

Для определения отношения следования вводятся логичестке часы - всякая функция T(е) (где е - событие), такая что:
для любых е<sub>1</sub> и е<sub>2</sub>, e<sub>1</sub> → e<sub>2</sub> тогда и только тогда, когда T(e<sub>1</sub>)<T(e<sub>2</sub>).

Наиболее распростаненной реализацией механизма логических часов являетютя векторные часы [мартин][фридж] представляют из себя вектор целых чисел, по одному на каждый процесс продвижение и сравнение которых проедставляют из себя следующие процедуры:
    
* При наступлении события e в процессе P<sub>i</sub>, i-компонента увеличивается на 1
* При отсылке сообщения из процесса P<sub>i</sub>, i-компонента увеличивается на 1
* При принятии сообщения процессом P<sub>j</sub>, j-компонента увеличивается на 1
    
Векторные часы V<sub>1</sub><V<sub>2</sub> тогда и только тогда, когда каждый компонент V<sub>2</sub> больше или равен соответсвующему компоненту V<sub>1</sub>.

В случае, когда события в процессах представляют из себя изменения и соглосование данных картина несколько изменяется. Передача сообщений имеет смысл синхронизации, потому данные, соответсвующие событиям отправки и получения должны быть одинаковы (прично-следственно эквивалентны). Типичная реализация отслеживания отношений между данными представляет из себя вектор версий [[19]] (https://en.wikipedia.org/wiki/Version_vector) - аналог векторных часов, но в отличии от них _при посыке или получении сообщений компоненты вектора не инкрементируются_, а берется максимум для каждой мары соответсвующих компонент, что естественным образом отражает действие по согласованию данных.
        
## Практические оценки размерности.

Эмпирические исследования по анализу размерностей посетов, образующихся реальными распределенными системами показывают, что в действительности размерности таких посетов на порядки меньше максимально возможного значения. В частности стандарный пример посета "корона" S(0, n), имеющий размерность n, если рассматривать его в контексте взаимодействующих процессов, являет собой атомарную широковещательную рассылку сообщений и, одновременный же, широковещательный прием этих сообщений. Появление такой фигуры крайне необычно на практике, хотя формально не нарушает приведенную модель.

В работе [[20]](https://ieeexplore.ieee.org/document/797397/) дана приближенная оценка реального значения размерности большого числа распределенных систем, на основании которых можно заключить что в действительности размерность посетов гораздо меньше теоретической оценки. Например для 1500+ процессов размерность была 10. В дальнейшем авторами были предприняты попыки [[21]](https://pdfs.semanticscholar.org/b4ed/53e58111737a6f4dfee98c15385c8b4aa1cf.pdf) [[22]](https://pdfs.semanticscholar.org/d0c2/401ea2440f983c878414414d55f0130f8197.pdf) генерации часов на основе жадного построения реалайзера, размер которого гораздо меньше векторных часов, которые могли бы быть применины. К сожалению, работа не была доведена до логического конца, а кроме того такой подход требовал глобального видения (в отличии от векторов версий).

Из подобных исследований можно сделать вывод что причинностные связи в реальных распределенных системах могут отслеживаться струкурами данных, занимающих гораздо меньше места, чем размерность образуемого посета. 

Авторы статьи(ей) пошли немного другим путем: 

1. Предполагая что определенные фигуры в образуемых посетах либо не могут появиться на практике, либо могут быть искусственно удалены.
2. Предприняв сокращение посетов и перебрав для фиксированного количества процессов все возможные конфигурации выяснить, каким образом процессам необходимо синхронизироваться, чтобы результирующий посет оставался размерности 2.
3. Исследовав полученные конфигурации, вывести правила и закономерности, следуя которым, синхронизирющиеся процессы будут всегда образовывать посет размерности 2.
4. Использовав такие правила вывести строгие точные логические часы потребляющие O(1) памяти.
    
## Вид изучаемых посетов. Приведение к каноническому виду.

Опишем преобразования и сведение посетов к каноническому виду.

Преобразование A:
Существует один тонкий момент при моделировании системы, где процессы модифицируют и согласуют данные. На практике посыл/поучение происходит в несколько этапов: 
    
1. процесс инициирующий согласование отсылает данные, 
2. парный процесс эти данные получает и синхронизирует локальную копию с присланной
3. в свою очередь парный процесс  отсылает собственные данные для сверки
4. инициирующий процесс получает и синхронизирует данные.

Для простоты, можно зафиксировать требование того, что между последовательной отправкой/получением для инициирующго процесса (и получением/отправкой для парного к нему процесса) не происходит локальных изменений данных . Диаграмма выполнеия таких процессов будет выглядить следующим образом ("квадрат синхронизации"): [рисунок изменить поставить точки и стрелки](https://pp.userapi.com/c846320/v846320295/40822/rJ_8zUG4IMA.jpg)
Такой квадрат синхронизации можно стянуть в 2 синхронизированные точки, получая классическую форму синхронизирующихся процессов [рисунок изменить соответственно](https://pp.userapi.com/c830209/v830209295/ed871/WGPuJA4PVu8.jpg)

Однако такая форма уже не будет являться посетом, а будет образовывать _предпорядок_. Для того чтобы обратно получить посет, заменим синхронизирующее друнаправленное ребро на точку, а исходящие/входящие точки раздвоим, и проведем ребра в соответсвии с семантикой: [рисунок](https://pp.userapi.com/c831508/v831508295/eded1/C-5lC8avr7U.jpg).

Таким образом преобразование А будет заключатся в замене квадрата синхронизации на join/fork фигуру [рисунок](https://pp.userapi.com/c846217/v846217295/3db5d/bFMcN4UVlfA.jpg). Далее на рисунках под ребром <--->, будет пониматься именно такая join/fork фигура.

Преобразование B:
Рассмотрев 4 различных случая возможного появления критических пар между синхронизирующимися процессами ([рисунок](https://sun1-4.userapi.com/c840520/v840520295/7c3b6/ekQnVcQebIU.jpg)), можно заметить следующее: 2 процесса между синхронизациями образуют не более 2х критических пар. Самый общий случай из них показан на рисунке [рисунок](https://pp.userapi.com/c845421/v845421295/40f68/eVxtsHXcs08.jpg). 

Используя данные замечания для анализа критических пар достаточно между синхронизациями производить только по одной локальной модифкации (т.е. добавляется одна точка). Критические пары будут образовываться на этих точках()[рисунок]

Положение критических пар при преобразовании А является инвариантным, т.к. он не изменяет отношения порядка для точек, лежащих между синхронизациями. Начальные точки критических пар находятся в точках завершающих синхронизацию, а конечные - в точках синхронизацию начинающих (рисунок)[рисунок]. Это можно проверить заметив что, во первых, критические пары не могут иметь начальную точку до синхронизации, а конечную после. Во вторых что между синхронизациями все точки не находтяся в отношении предшествования, а значит возможные начальными и конечными точками критических пар могут быть только те, что лежат непосредственно после и перед синхронизацией.

Изучаемые посеты будут иметь только фиксированное количество процессов. Примеры [рисунок](https://pp.userapi.com/c845417/v845417295/43044/UiPzahUa66A.jpg) [рисунок](https://pp.userapi.com/c846420/v846420295/3e0af/HyyBzJ3yiwk.jpg) [рисунок](https://pp.userapi.com/c846523/v846523295/3e1a3/n-ikwg42HSc.jpg)

Это и буду исследуемые нами посеты.

## Дополнительне определения

**Фронтир** - это такое множество F точек посета P, которые образуется при выполнении синхронизирующихся процессов, которые могут существовать в этом выполнении _одновременно_. В нашей модели, любые две точки, соединенные связанным направленным путем не могут принадлежать одному фронтиру. Нетрудно также догадаться что размер фронтира будет равен количеству процессов.

Рассмотрим два фронтира F<sub>1</sub> и F<sub>2</sub>. В случае если, каждый элемент F<sub>1</sub> предшевствует каждому из F<sub>2</sub>, будем говорить что F<sub>1</sub> предшевствует или _полностью синхронизирован_ с F<sub>2</sub>. Если два фронтира F<sub>1</sub> и F<sub>2</sub> полностью синхронезированны друг с другом, то посет заключенный между F<sub>1</sub> и F<sub>2</sub> будем назвать **Полностью Синхронизированным Исполнением (ПСИ)**. Обозначим его **Ψ(N, S)**, где N это количество процессов, S - количество синхронизаций.
[рисунок и объяснение на его примере!]

Если при этом не найдется отличного от них F<sub>1</sub> и F<sub>2</sub> фронтира F<sub>3</sub>, котороый не был бы синхронизирован с одним, но был бы синхронизированн с другим, то посет заключенный между F<sub>1</sub> и F<sub>2</sub> будем назвать **Минимальным Полностью Синхронизированным Исполнением (мПСИ)** и обозначать **mΨ(N, S)**. Примеры mΨ(3, 3) с выделенными фронтирами на [рисунке](https://pp.userapi.com/c846321/v846321295/3d0a1/uhkwMLUBqJg.jpg) и [рисунке](https://pp.userapi.com/c845219/v845219295/414dc/IN1HJ23jiFw.jpg).

Для фиксированного количества процессов N в начальном состоянии, минимальное количество синхронизаций, которое необхоимо провести, чтобы получить mΨ(N, S) вычисляется по формуле:

count(N) == N, если N четно
count(N) == N+1, если N нечетно

#### (Де)Композиция ПСИ (Ψ-(де)композиция).
Если взять два или более mΨ(N, S), и последовательно соединяя соответственно начальные и конецные точки (т.е. отождествляя последний и первый фронтиры) получим последовательную Ψ-композицию. Нетрудно убедится, что при такой операции внутри посета будут образовываться Ψ, отличные от образующих, и лежащих в пределах их начального и конечного фронтиров. 

Операция декомпозиции состоит в том, что от данного посета последовательно отделяются mΨ. Полученная при этом последовательность mΨ, опять же, может быть не уникальной.

Размерностью dim(Ψ), будет размерность соответсвующего ей посета.

Таким образом _размерностью посета_ будет _максимальная размерность Ψ_ среди всех возможных Ψ-декомпозициях для него. *** (это главная теорема блеать) ***

## Изоморфизм Ψ.

#### Базовый изоморфизм.
Рассматриваемые Ψ-посеты изоморфны с точностью до перестановок процессов.

Два различных Ψ<sub>1</sub>(N, S) и Ψ<sub>2</sub>(N, S) будут изоморфными, если существует такая перестановка p номеров N процессов из, что при применнении её к Ψ<sub>1</sub> получим Ψ<sub>2</sub>.

Процесс определения изоморфности двух Ψ достаточно прост: нужно перебрать все перестановки и последовательно сравнить синхронизации. Однако данный процесс является непрактичным, потому далее будем использовать другой способ определения изоморфизма.

Пример двух пар изоморфных mΨ приведен на [рисунок] (рисунок) [рисунок] (рисунок).

#### Изоморфизм по синхронизациям.
Для каждого процесса по мере работы системы ведется имя: в начале оно пустое, а при каждой синхронизации к нему добавляется глобальный номер этой синхронизации. Такое имя однозначно определяет положение процесса во всем исполнении (исключая тривиальные случаи). Если сравнить множестово имен процессов для двух Ψ, то окажется что если они эквиваленты, то эти Ψ равны.

Взяв полиномиальных хэш от отсортированных имен процессов получим хэш для Ψ.

***(расширенное описание, доказательство)***
    
## Нахождение посетов размерности 2.

Опишем процесс нахождения Ψ размерности 2.

#### Базовая процедура

* Зафиксируем количество процессов N, и положим что в каждом процессе произошло по одному событию. Это будет начальной конфигурацией.
* Запустим backtrack процедуру, которая на каждом шаге перебирает все пары процессов, синхронизирует эту пару и рекурсивно запускает себя дальше.
* Критерием останова будет достижение определенного наперед задонного количества синхронизаций. При его достижении происходит проверка, будет ли иметь полученный посет размерность 2.

Некоторые оптимизации позволяют резко сократить перебор и сильно увеличить скорость поиска:
* Проверять получающийся посет можно на кадом шаге перебора, тем самым отсечь заведомо неподходящие посеты.
* Количество изоморфных посетов с увеличеним N растет как Θ(N!). Использовав кэш в виде хэш-таблицы и хэшируя получающиеся посеты, можно добиться огромного отсечения при переборе. При этом, однако резко увеличивается потребление памяти.
* Процедура легко параллелится при помощи техник fork/join паралеллизма с котролем ветвления.

Процессы в Ψ<sub>i</sub>(N, S) занумерованны от 0 до N-1. В backtrack процедуре пары процессов для синхронизации генирируются в лексикографичестком порядке, например <0,1>, <0,2>, ..., <0,N>,<1,0>, ... ,<1,N>, ..., ..., <N-1, N>. Этот порядок порождает и лексикографический порядок для генирируемых Ψ. Потому имеет место запись Ψ<sub>i</sub>(N, S)#K, где K порядковый номер Ψ следи всех Ψ(N, S). Пример нескольких упорядоченных Ψ приведен на рисунке [рисунок](рисунок).

#### Проверка на размерность 2

Как уже было сказанно в разделе **X**, для определения того что посет имеет размерность 2 существует полиномиальный алгоритм. Наивная реализация имеет временную сложность O(N<sup>5</sup>) где N это количестов событий в исполнении, и состоит из следующих шагов:

##### Шаг 1. Нахождение всех критических пар
* На основе данного посета строится ориентированный граф с вершинами - точками посета, и ориентированными ребрами между парами вершин, непосредственно находящимися в отношении следования.
* С помощью алгоритма Флойда нахождения кратчайших путей между всеми парами вершин полученный граф достраивается до графа достижимости для данного посета.
* Перебираются все пары вершин графа достижимости, и используя следствие из определения критической пары, проверяется, образуют ли они критическую пару.

##### Шаг 2. Генерация графа несовместных критических пар
* Две критические пары не могут лежать в одном линейном расширении если при их обращении в посет перестанет быть посетом. Это возможно только в том случае если при обращении образуется ориентированный цикл в графе достижимости (**доказательство**). Используя этот признак,  перебирая все критические пары строится граф несовместных критических пар.

##### Шаг 3. Проверка полученного графа на двудольность.
* Двудольность графа проверяется поиском в глубину и попутным разбиением вершин на 2 класса. Если в процессе поиска вершину необходимо отнести сразу к двум классам граф считается недвудольным. Запуски генерации показали, что практической необходимости в распараллеливании или какой либо оптимизации нет, т.к. основной объем времени занимает непосредственно перебор.

## Результаты поиска

Осуществив проверку и генерацию Ψ с количеством процессов от 2 до 7 предложим некоторую классификацию полученных фигур.

По возможности построения путем композиции можно разделить на:

 * **Общие** - фигуры, которые сохраняют размерность 2 при Ψ-композиции кака саим с собой, так и между друг другом.
 * **Частные** - все осталные, т.е. те что нарушают свойство размерности при Ψ-композиции.

По своей структуре Ψ можно разделить на:
 * **Регулярные** - фигуры, в которых четко просматривается структура и алгоритм, по которому выбираются пары для синхронизации.
 * **Хаотичные** - неструктурированные фигуры, для которых нет возможности умозрительно определить алгоритм синхронизаций.
 * **Полурегулярные** - неструктурированные, для которых однако можно определенным образом построить Ψ-композиции.

Кроме машинного перебора всех возможных фигур Ψ(N, S) ввиду практической возможности и простоты осуществлялся также ручной анализ Ψ(3, X). Тривиальный случай Ψ(2, X) рассматривать не будем - два процесса всегда образуют посет размерности 2.

##### Ψ(3, S)
Три процесса полностью синхронизируются при помощи 3х синхронизаций и образуют ровно две различных фигуры, изображенных на рисунке [рисунок](). Первая фигура является случаем полской сетки, описанной ниже. Кроме машинной проверки оба случая были проверенны вручную построением риалайзера. Композиция этих фигур также всегда будет размерности 2. Обе фигуры можно отнести к регулярным общим.

##### Ψ(4, S)
Для четырех процессов требуется минимум 5 синхронизаций. Образуются 10 различных фигур [рисунки](), причем 2 (#9 и №10) из них содержат _параллельные синхронизации_, т.е. синхронизации, точки которых не состоят в отношении следования, и могут выполнятся в любом порядке друг относительно друга. 
**(детальное описание всех) **

##### Ψ(5, S)

##### Ψ(6, S) 

##### Плоская сетка 
Определив тотальный порядок среди процессов, синхронизироваться можно только с соседом справа и слева.
    
#####  Gather-Scatter
Начиная с "крайних" собирается в одной точке, потом по томуже маршруту раскидывается обратно.
    
##### Лесенка
Один синхронизирует всех?

## Определение причино-следственной связи ("Часы")

7.1 Для плоской сетки
    Придумать!
    
7.2 Gather-scatter
    Придумать
    
7.3 Синхронизации 3х
    Придумать!
    
## Список ссылок и литературы

 1.  _Brewer, Eric A._  [A Certain Freedom: Thoughts on the CAP Theorem](http://portal.acm.org/ft_gateway.cfm?id=1835701&type=pdf&CFID=25475815)  (англ.) // Proceeding of the XXIX ACM SIGACT-SIGOPS symposium on Principles of distributed computing. — N. Y.: [ACM](https://ru.wikipedia.org/wiki/ACM "ACM"), 2010. — Iss. 29. — No. 1. — P. 335—336.
 2. [Vogels, W.](https://en.wikipedia.org/wiki/Werner_Vogels "Werner Vogels")  (2009). "Eventually consistent".  _Communications of the ACM_.  **52**: 40.  [doi](https://en.wikipedia.org/wiki/Digital_object_identifier "Digital object identifier"):[10.1145/1435417.1435432](https://doi.org/10.1145%2F1435417.1435432).
 3. Saito, Yasushi; Shapiro, Marc (2005). "Optimistic replication". _[ACM Computing Surveys](https://en.wikipedia.org/wiki/ACM_Computing_Surveys "ACM Computing Surveys")_. **37** (1): 42–81. [doi](https://en.wikipedia.org/wiki/Digital_object_identifier "Digital object identifier"):[10.1145/1057977.1057980](https://doi.org/10.1145%2F1057977.1057980).
 4. Mattern, Friedman. (October 1988), "Virtual Time and Global States of Distributed Systems", in Cosnard, M., _Proc. Workshop on Parallel and Distributed Algorithms_, Chateau de Bonas, France: Elsevier, pp. 215–226
 5. Colin J. Fidge (February 1988). ["Timestamps in Message-Passing Systems That Preserve the Partial Ordering"](http://zoo.cs.yale.edu/classes/cs426/2012/lab/bib/fidge88timestamps.pdf)  (PDF). In K. Raymond (Ed.). _Proc. of the 11th Australian Computer Science Conference (ACSC'88)
 6. Nuno Preguiça, Carlos Baquero, Paulo Almeida, Victor Fonte and Ricardo Gonçalves. Brief Announcement: Efficient Causality Tracking in Distributed Storage Systems With Dotted Version Vectors. ACM PODC, pp. 335-336, 2012.
 7. ByungHoon Kang, Robert Wilensky, and John Kubiatowicz. The Hash History Approach for Reconciling Mutual Inconsistency. ICDCS, pp. 670-677, IEEE Computer Society, 2003.
 8. Paulo Almeida, Carlos Baquero and Victor Fonte. Version Stamps: Decentralized Version Vectors. ICDCS, pp. 544-551, 2002.
 9. https://haslab.wordpress.com/2011/07/08/version-vectors-are-not-vector-clocks/
 10. Lee, Conrad,  Nick, Bobo,  Brandes, Ulrik,  Cunningham, Pádraig : Link Prediction with Social Vector Clocks. In: Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2013-08-14.
 11. Bernadette Charron-Bost. Concerning the size of logical clocks in distributed systems. Journal Information Processing Letters, Volume 39, Issue 1, July 12, 1991, Pages 11-16.
 12. Leslie Lamport . Time, clocks, and the ordering of events in a distributed system. Comm. ACM 21, 7 (July 1978), 558 - 565.
 13. Szpilrajn, E. (1930), ["Sur l'extension de l'ordre partiel"](http://matwbn.icm.edu.pl/tresc.php?wyd=1&tom=16), _[Fundamenta Mathematicae](https://en.wikipedia.org/wiki/Fundamenta_Mathematicae "Fundamenta Mathematicae")_, **16**: 386–389
 14. [Dilworth, Robert P.](https://en.wikipedia.org/wiki/Robert_P._Dilworth "Robert P. Dilworth") (1950), "A Decomposition Theorem for Partially Ordered Sets", _[Annals of Mathematics](https://en.wikipedia.org/wiki/Annals_of_Mathematics "Annals of Mathematics")_, **51** (1): 161–166
 15. Dushnik, Ben & Miller, E. W. (1941), "[Partially Ordered Sets](https://www.jstor.org/stable/2371374)", _[American Journal of Mathematics](https://ru.wikipedia.org/wiki/American_Journal_of_Mathematics "American Journal of Mathematics")_ Т. 63 (3): 600-610
 16. T. Hiragushi, On the dimension of orders, Tech. Rept., University of Kanazawa, 1955.
 17. Mihalis Yannakakis, The Complexity of the Partial Order Dimension Problem, [SIAM Journal on Algebraic and Discrete Methods](https://www.researchgate.net/journal/0196-5212_SIAM_Journal_on_Algebraic_and_Discrete_Methods)3(3):351-358 · September 1982
 18. Stefan Felsner, William T. Trotter. Dimension, Graph and Hypergraph Coloring. June 2000, Volume  17, pp 167–177
 19. Douglas Parker, Gerald Popek, Gerard Rudisin, Allen Stoughton, Bruce Walker, Evelyn Walton, Johanna Chow, David Edwards, Stephen Kiser, and [Charles Kline](https://en.wikipedia.org/w/index.php?title=Charles_S._Kline&action=edit&redlink=1 "Charles S. Kline (page does not exist)"). Detection of mutual inconsistency in distributed systems. Transactions on Software Engineering. 1983
 20. P.A.S. Ward. # An offline algorithm for dimension-bound analysis. Parallel Processing, 1999. Proceedings. 1999 International Conference on. 24-24 Sept. 1999
 21. Paul A. S. Ward. A framework algorithm for dynamic, centralized dimension-bounded timestamps. Proceeding CASCON '00 Proceedings of the 2000 conference of the Centre for Advanced Studies on Collaborative research Page 14
 22. Paul A.S. Ward, David J. Taylor. A Hierarchical Cluster Algorithm for Dynamic, Centralized Timestamps. Proceeding ICDCS '01 Proceedings of the The 21st International Conference on Distributed Computing Systems, Page 585. 
 23. Shapiro, Marc; Preguiça, Nuno; Baquero, Carlos; Zawirski, Marek (13 January 2011). "A Comprehensive Study of Convergent and Commutative Replicated Data Types". _RR-7506_. HAL - Inria.
 24. Vitor Enes, Carlos Baquero, Paulo Sérgio Almeida, Ali Shoker. Join Decompositions for Efficient Synchronization of CRDTs after a Network Partition: Work in progress report. Proceeding [PMLDC '16](http://2016.ecoop.org/track/PMLDC-2016 "Conference Website")  First Workshop on Programming Models and Languages for Distributed Computing, Article No. 6.
