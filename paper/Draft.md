


План статей:
    Поиск и изучение посетов размерности 2, возникающих при синхронизациях параллельных процессов.
    Выявление паттернов.
    Генерация определителей П/С связей ("часов").
    
### Абстракт.

Изучаем минимальные по потреблению памяти способы отслеживания причинности для реплицированных данных в распределенных системах.
Изучаем схемы синхронизаций, образующие посеты размерности 2.
    
## Описание проблемы, актулаизация.

С кардинальным ростом нагрузок на хранилища данных (требование к обработке больших количеств запросов на запись и чтение) возникает потребность перехода на парадигмы в области архитектуры СУБД, отличные от центральный сервер - клиенты. 
Amazon Dynamo[], Cassandra[] и Riak[] являются яркими представителями таких СУБД, архитектура которых сосредоточенна на _усточивости к разделению_, _доступности для чтения/записи_ и _согласованности в конечном_итоге_. 

Подобные распределенные системы лежат в области действия эвристической теоремы CAP[], утверждающей что среди требований _согласованности_ (1), _доступности_(2) и  _устойчивости к разделению_ (3) одновременно можно достич только 2х.

Кроме того возникают дополнительные требования, в виде массовой репликации - для достижения распределения нагрузки, децентрализации и большему повышению доступности и гео-распределенности - системы хранения данных становятся глобальными.
Принимая во внимание дополнительные требования неизбежным является ослабление ограничений _согласованности_ - со строгой согласованности до согласованности в конечном итоге[].

Подобные системы следуют дизайну, где данные всегда могут быть записанны: копиям (репликам) одних и техже данных на разных узлах позволено быть частично отличными. Однако в зависимотсти от способа синхронизаций могут происходить конфликты, наподобии возникновения нескольких конкуррентных копий либо потерянных обновлений данных. 
    Пример кассандры
    Пример динамо

Для поддержания полной согласованности и возможности синхронизаций копий используются различные механизмы отслеживания причинно-следственных зависимостей в данных[]. Наиболее распространенный и известный - version vector[], однако линейно зависит по памяти от количества реплик, а потому не ожет быть эффективно использован в системах с массовой репликацией.

За последнее время создано немало альтернатив, одни из которых являются вариацией на тему вектора версий, другие же используют принципиально иной подход.
Среди них можно выделить:

* Dotted Version Vector. Пожалуй наиболее практичный из всех. Основывается на принципе выделения специального подмножества (серверных) узлов, которые непосредственно отслежыивают прицинностную информацию и концепцию точек (dots), призванную отличать пропуски в обновлениях, совершенных на не "серверных узлах". Уменьшая количество информации использование DVV делает систему неполноценно P2P, точек пораждает необходимость хранить полые данные дял этих точек.
    
* Hash Histories. Полностью хранит посет исполнения (см. ниже) в виде графа с узлами, содержащими хэш от данных. С одной стороны содержит избыточную информацию, с другой - имеет возможность обнаружения одинаковых копий, которое не следует из причинных связей.
    
* Version stamps. Основывается на принципе динамичекого выведения идентификаторов для узлов, которое одновременно служит и способом отличать параллельные событи от зависимых. Объем дополнительных данных линейно зависит от количества обновлений и синхронизаций.
    
* Эти способы относятся к классу _точных_ - т.е. в любом случае корректно определяют причинностные отношения между двумя копиями.
    
* Также существуют неточные - для которых не всегда можно утверждать (либо утверждать с вероятностью < 1) паралелльны ли данные или находятся в причинно-следственной связи. И способы, полагающиеся на определенную топологию сети.

Важно также отметить связть между отслеживанием причинности и логическиеми часами. Первое можно рассматривать как частный случай логических часов, потому в определенной степени варианты таких часов могут быть рассмотрены в настоящем контексте [ссылки на часы]. Об этой связи подробнее ниже[].

Кроме всего прочего, отслеживание информации о причинностных связях использует в других областях знаний, в частности социологии[] и исследовании социальных сетей[] и недостатки, в частности VV, проявляются там особенно остро.


>>>>>>ВВВЕДЕНИЕ ВООБЩЕ

Данная работа ставит целью изучение возможности и способов понизить накладные расходы по памяти при отслеживании причинностных связей при сохранении точностью, а также выведения практически применимых схем построения метаинформации. Учитываю известные оценки сложности[] (подробнее в главе Х) описывается и анализируется определенный класс моделей.

Исследуя синхронизирующиеся процессы в модели Лэмпорта[], описанные в главе Х, обнаруживается возможность сведения задачи к рассмотрению некоторого набора параметризированных конфигураций синхронизирующихся процессов (главы Х и Y). Варьирую параметр отвечающий за количество процессов выведенны некотроые свйоства для N = 3, 4, 5 и 6 (глава X). Основываясь на полученных результатах предпринята попытка вывести схему постноения метаинформации (глава X)

	Распределенные БД, необходимость масштабирования (в т.ч. географического), необходимость поддержания согласованности.
    CRDT, во всех ипостасях (как таковые, так и в БД вообще), необходимость отслеживания ПС для CRDT. Отсылка к социологоии.
            
	Описание способов отслеживания причинно-следственной истории. VersionVector, Dotted Version Vector, Hash Histories, Dynamic ForkJoin.
    Недостатки существующих метаинформаций, сравнение. (зависимость либо от N либо от U)
            
            
>>>>>>>>>>>>Введение CRDT

Время прошло, обобщился опыт.
ЦРДТ это обобщение подходов к согласованной в конечном счете репликаций. 
Два типа.
Используются в тамто и тамто.
Для типа с состоянием необходима метаинформация о причинности между данными.
Используют DVV.
Для оптимизации протокола антиэнтропии ищем минимальный по объему.
    
   
## Краткое описание схемы статьи.

Темы статей по материалу (по степени важности/уменьшения объема):

1. Вывод оптимального алгоритма антиэнтропии для CRDT. Оптимальность заключается в минимизации накладных расходов на поддержание метаинформации. Отслеживаем причинностную информацию посетами минимальной размерности.

2. Генерация синхронизирующихся процессов размерности 2. 
        Описать сведение задачи, алгоритм генерации и спосоы композиции.
        
3. Алгоритм проверки посета на размерность == 2
    
4. Изоморфизм посетов синхронизирующихся процессов.
        
То о чем в данной статье рассказывается. Схема статьи, её карта.
    

## Понятия и определения.

Приведем необходимые в дальнейшем понятия, определения и теоремы.

Множество P, c заданным на нем бинарном отношение , обладающее свойствами рефлексивности и транзитивности называется _предпорядком_.

**Частично упорядоченное множество** (ЧУМ, посет (от англ. partially ordered set - poset)): множество P с введенным на нем бинарным отношением ≤, удовлетворяющим аксиомам рефлексивности, антисимметричности и транзитивности. Формально, для любых a, b и c принадлежащим P должно выполнятся.

В статье для краткости используется калька с английского - **посет** (poset) - в качестве альтернативы ЧУМ.

1. a ≤ a (рефлексивность - каждый элемент сравним сам с собой)
2. если a ≤ b и b ≤ a, то a=b (антисимметричность - два различных элемента не могут быть сравнимы только с одной стороны)
3. если a ≤ b и b ≤ c, тогда a ≤ c(два элемента сравнимы через третий транзитивно)
    
Самое отношение ≤ называют отношением частичного порядка.

Для удобства в рамках данной статьи для обозначения частичного порядка будем использовать символ →.

Для любых двух элементов а и b ∈ (P, →) если a→b или b→a, то говорят что а и b сравнимы, иначе a и b несравнимы.

**Линейно (тотально) упорядоченное множество** - это посет, в котором любые два элемента сравнимы.
Такой посет также называют цепью. В свою очередь посет, в котором любые два элемента попарно несравнимы называют антицепью.

**Линейное расширение** (продолжение) - для посета (P, →) это такой линейний порядок (L, →), для которого выполняется:
    
1. L = P, базовые множества совпадают
2. если a→b в посете, то a→b в линейном порядке. линейное расширение сохраняет порядок посета.

Теорема 1 (Шпильрайна):
    Для любого посета существет линейное расширение.
    
Ширина посета - это количество элементов в максимальной антицепи. Формально:
    X ∈ P | X - антицепь, для любого Y ∈ P, Y - антицепь |X|>=|Y|,
    |X| - и есть ширина

Теорема 2 (Дилворта):
    Минимальное количество цепей, на которое можно разбить посет равно количеству элементов в максимально антицепи.
    
Отсюда второе определение ширины:

**Ширина посета** - минимальное количество цепей, на которое можно разбить посет
    
**Высота посета** - количество элементов в наидлиннейшей цепи. Формально
    X ∈ P | X - цепь, для любого Y ∈ P, Y - цепь |X|>=|Y|,
    |X| - есть длина
    
**Реалайзер** - для посета (P, →) набор линейных расширений, пересечение которых дает исходный посет P.

**Размерность посета** (P, →) - это риалайзер минимального размера.

Размерность принято обозначать **dim(P)**

Теорема 3 (Хирагучи):
    Размерность посета P не проевосходит его ширины.

**Критическая парa** элементов (a, b), это такая упорядоченная пара несравнимых элементов посета P, которые

* несравнимы
* для любого z ∈ P, из того что b→z, следует что a→z
* для любого z ∈ P, из того что z→a, следует что z→b
    
Следствие: если (a, b) критическая пара, то добавление отношения a→b к P остается частичным порядком, т.е. не нарушает требование транзитивности.

Линейное расширение L _реверсирует_ критическую пару (a, b) если для L верно что b→a.

Набор линейных расширений тогда будет являться риалайзером, когда каждая критическая пара будт обращена хотябы в одном из них.

По поводу вычисления размерности произвольного посета можно сказать следующее:

Утверждение X (Янакаккис[]) Задача определения того, что посет имеет размерность больше 2х является NP-полной.
Как следствие, для проверки того что посет имеет размерность меньше трех существет полиномиальный алгоритм.

**Гиперграф несовместных пар H(P)** это такой гиперграф, в котором вершинами явлются несравнимые пары элементов P, а гиперребра строятся на тех множествах S несравнимых пар, для которых выполняется:
    
a. Ниодно линейное расширение не реверсирует одновременно все элементы S.
b. Если T собственное подмножество S, то существует линейное расширение P, которое реверсирует все несравнимые пары.

Таки образом гиперребрами будут  те минимальне наборы несравнимых пар, которые нельзя одновременно обратить в одном линейном расширении.

**Графом несовместных пар G(P)** будет назваться пограф H(P) с ребрами размера 2.

**Гиперграф несовместных критических пар H<sub>c</sub>(P)** это подграф H(P), в котором оставлены только вершины - критические пары.

Аналогично **граф несовместных критических пар G<sub>c</sub>(P)** это подграф G(P), построенный только на критических парах.

**Хроматическое число χ(H)** (гипер)графа H - это минимальное число k, такое что множество вершин графа можно разбить на k непересекающихся классов.

Для (гипер)графов несовместных и критических пар верны следующие неравенства:
    dim(P) == χ(H) == χ(H<sub>c</sub>) >= χ(G) == χ(G<sub>c</sub>)    
   
Теорема Х (Троттер):
    Если граф G<sub>c</sub>(P) это граф несовместных критических пар посета P, который не является линейным порядком. Тогда размерность посета P будет равна 2 если, и только если χ(G) == 2.

## Моделирование посетов.

Системная модель.

В основе лежит классическа асинхронная распеределенная система, модель, состоящая из N распределенных процессов P<sub>1</sub> ...P<sub>N</sub>. Процессы не разделяют общие ресуры и сообщаются между собой путем парной передачи сообщений по сети, имеющей произвольную топологию. Коммуникация является асинхронной, с произвольно долгой, но предсказуемой задержкой. Важно что процессы не имеют доступа к глобальным часам и могут использованны только локальные часы.

Понятие времени в таких системах определяется тем, связанны ли события причинно-следственныи связями следующим образом:
    
1. Если два различных события е<sub>1</sub> и е<sub>2</sub> произошли в рамках одного процесса, и е<sub>1</sub> наступило раньше е<sub>2</sub>, то е<sub>1</sub> предшествует е<sub>2</sub>  (е<sub>1</sub> → e<sub>2</sub>).
2. Если е<sub>1</sub> это событие отправки сообщения, а е<sub>2</sub> событие получения, то е<sub>1</sub> предшествует е<sub>2</sub> (е<sub>1</sub> → e<sub>2</sub>).
3. Если е<sub>1</sub>, е<sub>2</sub> и е<sub>3</sub> различные события, (е<sub>1</sub> → e<sub>2</sub>) и (е<sub>2</sub> → e<sub>3</sub>), то е<sub>1</sub> предшествует е<sub>3</sub> (e<sub>1</sub> → e<sub>3</sub>).
    
Таким образом для событий распределенной системы вводится отношение частичного порядка →, которое отражает причинно следственные связи между ними. События, не связанные между собой отношением предшествования → быдем называть паралелльными e<sub>1</sub> || e<sub>2</sub>. Эту модель ввел Лесли Лэмпорт, под названием произошло до (англ. happens before) [ссылка].

Для определения отношения следования вводятся логичестке часы - всякая функция T(е) (где е - событие), такая что:
для любых е<sub>1</sub> и е<sub>2</sub>, e<sub>1</sub> → e<sub>2</sub> тогда и только тогда, когда T(e<sub>1</sub>)<T(e<sub>2</sub>).

Наиболее распростаненной реализацией механизма логических часов являетютя векторные часы [мартин][фридж] представляют из себя вектор целых чисел, по одному на каждый процесс продвижение и сравнение которых проедставляют из себя следующие процедуры:
    
* При наступлении события t в процессе P<sub>i</sub>, i-компонента увеличивается на 1
* При отсылке сообщения из процесса P<sub>i</sub>, i-компонента увеличивается на 1
* При принятии сообщения процессом P<sub>j</sub>, j-компонента увеличивается на 1
    
Векторные часы V<sub>1</sub><V<sub>2</sub> тогда и только тогда, когда каждый компонент V<sub>2</sub> больше или равен соответсвующему компоненту V<sub>1</sub>.

В случае, когда события в процессах представляют из себя изменения и соглосование данных картина несколько изменяется. Передача сообщений имеет смысл синхронизации, потому данные, соответсвующие событиям отправки и получения должны быть одинаковы (прично-следственно эквивалентны). Типичная реализация отслеживания отношений между данными представляет из себя вектор версий[ссылка] - аналог векторных часов, но в отличии от них _при посыке или получении сообщений компоненты вектора не инкрементируются_, а берется максимум для каждой мары соответсвующих компонент, что естественным образом отражает действие по согласованию данных.
        
## Практические оценки размерности.

Эмпирические исследования по анализу размерностей посетов, образующихся реальными распределенными системами показывают, что в действительности размерности таких посетов на порядки меньше максимально возможного значения. В частности стандарный пример посета "корона" S(0, n), имеющий размерность n, если рассматривать его в контексте взаимодействующих процессов, являет собой атомарную широковещательную рассылку сообщений и, одновременный же, широковещательный прием этих сообщений. Появление такой фигуры крайне необычно на практике, хотя формально не нарушает приведенную модель.

В работе [ссылка An Offline Algorithm for Dimension-Bound Analysis] дана приближенная оценка реального значения размерности большого числа распределенных систем, на основании которых можно заключить что в действительности размерность посетов гораздо меньше теоретической оценки. Например для 1500+ процессов размерность была 10. В дальнейшем авторами были предприняты попыки [ссылки] генерации часов на основе жадного построения реалайзера, размер которого гораздо меньше векторных часов, которые могли бы быть применины. К сожалению, работа не была доведена до логического конца, а кроме того такой подход требовал глобального видения (в отличии от векторов версий).

Из подобных исследований можно сделать вывод что причинностные связи в реальных распределенных системах могут отслеживаться струкурами данных, занимающих гораздо меньше места, чем размерность образуемого посета. 

Авторы статьи(ей) пошли немного другим путем: 

1. Предполагая что определенные фигуры в образуемых посетах либо не могут появиться на практике, либо могут быть искусственно удалены.
2. Предприняв сокращение посетов и перебрав для фиксированного количества процессов все возможные конфигурации выяснить, каким образом процессам необходимо синхронизироваться, чтобы результирующий посет оставался размерности 2.
3. Исследовав полученные конфигурации, вывести правила и закономерности, следуя которым, синхронизирющиеся процессы будут всегда образовывать посет размерности 2.
4. Использовав такие правила вывести строгие точные логические часы потребляющие  O(1) памяти.
    
## Вид изучаемых посетов. Приведение к каноническому виду.

Опишем преобразования и сведение посетов к каноническому виду.

Преобразование A:
Существует один тонкий момент при моделировании системы, где процессы модифицируют и согласуют данные. На практике посыл/поучение происходит в несколько этапов: 
    
1. процесс инициирующий согласование отсылает данные, 
2. парный процесс эти данные получает и синхронизирует локальную копию с присланной
3. в свою очередь парный процесс  отсылает собственные данные для сверки
4. инициирующий процесс получает и синхронизирует данные.

Для простоты, можно зафиксировать требование того, что между последовательной отправкой/получением для инициирующго процесса (и получением/отправкой для парного к нему процесса) не происходит локальных изменений данных . Диаграмма выполнеия таких процессов будет выглядить следующим образом ("квадрат синхронизации"): [рисунок изменить поставить точки и стрелки](https://pp.userapi.com/c846320/v846320295/40822/rJ_8zUG4IMA.jpg)
Такой квадрат синхронизации можно стянуть в 2 синхронизированные точки, получая классическую форму синхронизирующихся процессов [рисунок изменить соответственно](https://pp.userapi.com/c830209/v830209295/ed871/WGPuJA4PVu8.jpg)

Однако такая форма уже не будет являться посетом, а будет образовывать _предпорядок_. Для того чтобы обратно получить посет, заменим синхронизирующее друнаправленное ребро на точку, а исходящие/входящие точки раздвоим, и проведем ребра в соответсвии с семантикой: [рисунок](https://pp.userapi.com/c831508/v831508295/eded1/C-5lC8avr7U.jpg).

Таким образом преобразование А будет заключатся в замене квадрата синхронизации на join/fork фигуру [рисунок](https://pp.userapi.com/c846217/v846217295/3db5d/bFMcN4UVlfA.jpg). Далее на рисунках под ребром <--->, будет пониматься именно такая join/fork фигура.

Преобразование B:
Рассмотрев 4 различных случая возможного появления критических пар между синхронизирующимися процессами ([рисунок](https://sun1-4.userapi.com/c840520/v840520295/7c3b6/ekQnVcQebIU.jpg)), можно заметить следующее: 2 процесса между синхронизациями образуют не более 2х критических пар. Самый общий случай из них показан на рисунке [рисунок](https://pp.userapi.com/c845421/v845421295/40f68/eVxtsHXcs08.jpg). 

Используя данные замечания для анализа критических пар достаточно между синхронизациями производить только по одной локальной модифкации (т.е. добавляется одна точка). Критические пары будут образовываться на этих точках()[рисунок]

Положение критических пар при преобразовании А является инвариантным, т.к. он не изменяет отношения порядка для точек, лежащих между синхронизациями. Начальные точки критических пар находятся в точках завершающих синхронизацию, а конечные - в точках синхронизацию начинающих (рисунок)[рисунок]. Это можно проверить заметив что, во первых, критические пары не могут иметь начальную точку до синхронизации, а конечную после. Во вторых что между синхронизациями все точки не находтяся в отношении предшествования, а значит возможные начальными и конечными точками критических пар могут быть только те, что лежат непосредственно после и перед синхронизацией.

Изучаемые посеты будут иметь только фиксированное количество процессов. Примеры [рисунок](https://pp.userapi.com/c845417/v845417295/43044/UiPzahUa66A.jpg) [рисунок](https://pp.userapi.com/c846420/v846420295/3e0af/HyyBzJ3yiwk.jpg) [рисунок](https://pp.userapi.com/c846523/v846523295/3e1a3/n-ikwg42HSc.jpg)

Это и буду исследуемые нами посеты.

## Дополнительне определения

**Фронтир** - это такое множество F точек посета P, которые образуется при выполнении синхронизирующихся процессов, которые могут существовать в этом выполнении _одновременно_. В нашей модели, любые две точки, соединенные связанным направленным путем не могут принадлежать одному фронтиру. Нетрудно также догадаться что размер фронтира будет равен количеству процессов.

Рассмотрим два фронтира F<sub>1</sub> и F<sub>2</sub>. В случае если, каждый элемент F<sub>1</sub> предшевствует каждому из F<sub>2</sub>, будем говорить что F<sub>1</sub> предшевствует или _полностью синхронизирован_ с F<sub>2</sub>. Если два фронтира F<sub>1</sub> и F<sub>2</sub> полностью синхронезированны друг с другом, то посет заключенный между F<sub>1</sub> и F<sub>2</sub> будем назвать **Полностью Синхронизированным Исполнением (ПСИ)**. Обозначим его **Ψ(N, S)**, где N это количество процессов, S - количество синхронизаций.
[рисунок и объяснение на его примере!]

Если при этом не найдется отличного от них F<sub>1</sub> и F<sub>2</sub> фронтира F<sub>3</sub>, котороый не был бы синхронизирован с одним, но был бы синхронизированн с другим, то посет заключенный между F<sub>1</sub> и F<sub>2</sub> будем назвать **Минимальным Полностью Синхронизированным Исполнением (мПСИ)** и обозначать **mΨ(N, S)**. Примеры mΨ(3, 3) с выделенными фронтирами на [рисунке](https://pp.userapi.com/c846321/v846321295/3d0a1/uhkwMLUBqJg.jpg) и [рисунке](https://pp.userapi.com/c845219/v845219295/414dc/IN1HJ23jiFw.jpg).

Для фиксированного количества процессов N в начальном состоянии, минимальное количество синхронизаций, которое необхоимо провести, чтобы получить mΨ(N, S) вычисляется по формуле:

count(N) == N, если N четно
count(N) == N+1, если N нечетно

#### (Де)Композиция ПСИ (Ψ-(де)композиция).
Если взять два или более mΨ(N, S), и последовательно соединяя соответственно начальные и конецные точки (т.е. отождествляя последний и первый фронтиры) получим последовательную Ψ-композицию. Нетрудно убедится, что при такой операции внутри посета будут образовываться Ψ, отличные от образующих, и лежащих в пределах их начального и конечного фронтиров. 

Операция декомпозиции состоит в том, что от данного посета последовательно отделяются mΨ. Полученная при этом последовательность mΨ, опять же, может быть не уникальной.

Размерностью dim(Ψ), будет размерность соответсвующего ей посета.

Таким образом _размерностью посета_ будет _максимальная размерность Ψ_ среди всех возможных Ψ-декомпозициях для него. *** (это главная теорема блеать) ***

## Изоморфизм Ψ.

#### Базовый изоморфизм.
Рассматриваемые Ψ-посеты изоморфны с точностью до перестановок процессов.

Два различных Ψ<sub>1</sub>(N, S) и Ψ<sub>2</sub>(N, S) будут изоморфными, если существует такая перестановка p номеров N процессов из, что при применнении её к Ψ<sub>1</sub> получим Ψ<sub>2</sub>.

Процесс определения изоморфности двух Ψ достаточно прост: нужно перебрать все перестановки и последовательно сравнить синхронизации. Однако данный процесс является непрактичным, потому далее будем использовать другой способ определения изоморфизма.

Пример двух пар изоморфных mΨ приведен на [рисунок] (рисунок) [рисунок] (рисунок).

#### Изоморфизм по синхронизациям.
Для каждого процесса по мере работы системы ведется имя: в начале оно пустое, а при каждой синхронизации к нему добавляется глобальный номер этой синхронизации. Такое имя однозначно определяет положение процесса во всем исполнении (исключая тривиальные случаи). Если сравнить множестово имен процессов для двух Ψ, то окажется что если они эквиваленты, то эти Ψ равны.

Взяв полиномиальных хэш от отсортированных имен процессов получим хэш для Ψ.

***(расширенное описание, доказательство)***
    
## Нахождение посетов размерности 2.

Опишем процесс нахождения Ψ размерности 2.

#### Базовая процедура

* Зафиксируем количество процессов N, и положим что в каждом процессе произошло по одному событию. Это будет начальной конфигурацией.
* Запустим backtrack процедуру, которая на каждом шаге перебирает все пары процессов, синхронизирует эту пару и рекурсивно запускает себя дальше.
* Критерием останова будет достижение определенного наперед задонного количества синхронизаций. При его достижении происходит проверка, будет ли иметь полученный посет размерность 2.

Некоторые оптимизации позволяют резко сократить перебор и сильно увеличить скорость поиска:
* Проверять получающийся посет можно на кадом шаге перебора, тем самым отсечь заведомо неподходящие посеты.
* Количество изоморфных посетов с увеличеним N растет как Θ(N!). Использовав кэш в виде хэш-таблицы и хэшируя получающиеся посеты, можно добиться огромного отсечения при переборе. При этом, однако резко увеличивается потребление памяти.
* Процедура легко параллелится при помощи техник fork/join паралеллизма с котролем ветвления.

Процессы в Ψ<sub>i</sub>(N, S) занумерованны от 0 до N-1. В backtrack процедуре пары процессов для синхронизации генирируются в лексикографичестком порядке, например <0,1>, <0,2>, ..., <0,N>,<1,0>, ... ,<1,N>, ..., ..., <N-1, N>. Этот порядок пораждает и лексикографический порядок для генирируемых Ψ. Потому имеет место запись Ψ<sub>i</sub>(N, S)#K, где K порядковый номер Ψ следи всех Ψ(N, S). Пример нескольких Ψ приведен на рисунке [рисунок](рисунок).

#### Проверка на размерность 2.
Как уже было сказанно в разделе **X**, для определения того что посет имеет размерность 2 существует полиномиальный алгоритм. Наивная реализация имеет временную сложность O(N<sup>5</sup>) и состоит из следующих шагов:
##### Шаг 1. Нахождение всех критических пар
* На основе данного посета строится ориентированный граф с вершинами - точками посета, и ориентированными ребрами между парами вершин, непосредственно находящимися в отношении следования.
* С помощью алгоритма Флойда нахождения кратчайших путей между всеми парами вершин полученный граф достраивается до графа достижимости для данного посета.
* Перебираются все пары вершин графа достижимости, и используя следствие из определения критической пары, проверяются образуют ли они критическую пару.
##### Шаг 2. Генерация графа несовместных критических пар
Две критические пары называются несовсместными если н
##### Шаг 3. Проверка полученного графа на двудольность

## Результаты поиска

Универсальные:

6.1 Плоская сетка
    Определив тотальный порязок среди процессов, синхронизироваться можно только с соседом справа и слева.
    
6.2 Gather-Scatter
    Начиная с "крайних" собирается в одной точке, потом по томуже маршруту раскидывается обратно.

Частные:
6.3 Синхронизация 3х
    3 процесса всегда иеют посет размерности 2
    
6.4 Синхронизация 4х
    Рассмотреть 10 случаев. Последовательная композиция тех или иных. Последовательная композиция с перестановками.
    
6.5 Синхронизация 5х
    Некоторые "хорошие" ПСИ.

## Определение причино-следственной связи ("Часы")

7.1 Для плоской сетки
    Придумать!
    
7.2 Gather-scatter
    Придумать
    
7.3 Синхронизации 3х
    Придумать!
    