
# I. В поисках оптимального алгоритма антиэнтропии для δ-CmRDT. Рабочий отчет.
# II. В поисках оптимального способа отслеживания причинностных связей в данных. Рабочий отчет.

### Абстракт.

Попытка решить проблему потребления памяти для механизмов отслеживания причинно-следственных связей. Изучаются минимальные по потреблению памяти способы отслеживания причинности для реплицированных данных в распределенных системах.
Изучаются схемы синхронизаций, образующие частично упорядоченные множества размерности 2. Описан алгоритм провеки таких частично упорядоченных множеств на размерность 2.
Найдены и представлены некоторые частные и общие схемы, при которых есть возможность построить требуемые механизмы.
    
## Описание проблемы, актулаизация.

С кардинальным ростом нагрузок на хранилища данных (требование к обработке больших количеств запросов на запись и чтение) возникает потребность перехода на парадигмы в области архитектуры СУБД, отличные от "центральный сервер - клиенты". 
[Amazon Dynamo](https://aws.amazon.com/dynamodb/)[26], [Cassandra](http://cassandra.apache.org/) и [Riak KV](http://basho.com/products/riak-kv/) являются яркими представителями таких СУБД, архитектура которых сфокусированна на _усточивости к разделению_, _доступности для чтения/записи_ и _согласованности в конечном итоге_. 

Подобные распределенные системы лежат в области действия эвристической теоремы CAP[1](https://en.wikipedia.org/wiki/CAP_theorem), утверждающей что среди требований _согласованности_, _доступности_ и  _устойчивости к разделению_ одновременно можно достич только 2х.

Кроме того, возникают дополнительные требования в виде _массовой репликации_ - для достижения распределения нагрузки, децентрализации и бóльшему повышению доступности и гео-распределенности - системы хранения данных становятся глобальными.
В таких условиях неизбежным является ослабление ограничений _согласованности_ - со строгой согласованности до [согласованности в конечном итоге](https://en.wikipedia.org/wiki/Eventual_consistency) [2][3].

Подобные системы следуют дизайну, где данные всегда могут быть записаны: копиям (репликам) одних и тех-же данных на разных узлах позволено быть частично отличными. Однако в зависимотсти от способа синхронизаций могут происходить конфликты, наподобии возникновения нескольких конкурентных копий либо потерянных обновлений данных. 

Для поддержания согласованности и возможности синхронизаций копий используются различные механизмы отслеживания причинно-следственных зависимостей в данных. Наиболее распространенный и известный - [Version Vector](https://en.wikipedia.org/wiki/Version_vector) [4][5], однако линейно зависит по памяти от количества реплик, а потому не может быть эффективно использован в системах с массовой репликацией.

За последнее время создано немало альтернатив, частично решающих проблему потребления памяти, одни из которых являются вариацией на тему вектора версий, другие же используют принципиально иной подход.
Среди них можно выделить:

* Dotted Version Vector[[6]](http://gsd.di.uminho.pt/members/vff/dotted-version-vectors-2012.pdf). Пожалуй, наиболее практичный из всех. Основывается на принципе выделения специального подмножества (серверных) узлов, которые непосредственно отслеживают причинностную информацию; и на концепции точек (dots), призванную отличать пропуски в обновлениях, совершенных на не "серверных" узлах. Уменьшая требуемый объем памяти, использование DVV делает систему неполноценно p2p, а точки пораждают необходимость хранить полые данные для этих точек.
    
* Hash Histories[[7]](http://oceanstore.cs.berkeley.edu/publications/papers/pdf/hh_icdcs03_kang.pdf). Полностью хранит граф исполнения с узлами, содержащими хэш от данных. С одной стороны содержит избыточную информацию, с другой - имеет возможность обнаружения одинаковых копий, оказавшихся таковыми случайно, и чего не следует из причинностных связей.
    
* Version stamps[[8]](http://haslab.uminho.pt/cbm/files/10.1.1.16.8235.pdf). Основывается на принципе динамичекого выведения идентификаторов для узлов, которое одновременно служит и способом отличать параллельные событи от зависимых. Объем дополнительных данных линейно зависит от количества обновлений и синхронизаций.
    
* Эти способы относятся к классу _точных_ - т.е. в любом случае корректно определяют причинностные отношения между двумя копиями.
    
* Также существуют неточные - для которых не всегда можно утверждать (либо утверждать с вероятностью < 1) конкурентны ли данные или находятся в причинно-следственной связи. 

* И способы, полагающиеся на определенную топологию сети.

Важно также отметить связь между отслеживанием причинности и логическими часами. Первое можно рассматривать как частный случай логических часов, потому в определенной степени варианты таких часов могут быть рассмотрены в настоящем контексте [[9]](https://haslab.wordpress.com/2011/07/08/version-vectors-are-not-vector-clocks/) . Об этой связи подробнее ниже.

Кроме всего прочего, отслеживание информации о причинностных связях используют в других областях знаний, в частности социологии и исследовании социальных сетей [[10]](https://arxiv.org/pdf/1304.4058.pdf) и недостатки, в частности version vector, проявляются там особенно остро.

## CRDT

Основываясь на опыте распределенных баз данных с master-master репликацией и обобщая способы согласования данных в системах с нестрогим согласованием данных были выведены Безконфликтные Реплицируемые Структуры Данных (англ. CRDT - Conflict Free Replicated Data Types). Использование таких структур гарантируют _строгую_ согласованность в конечном итоге [3]. Кроме прочего, CRDT в явном виде уже использует, или собираются вводить множество крупных собременных СУБД: например Microsoft Cosmos DB [[28]](https://docs.microsoft.com/en-us/azure/cosmos-db/multi-region-writers), Redis [[27]](http://lp.redislabs.com/rs/915-NFD-128/images/WP-RedisLabs-Redis-Conflict-free-Replicated-Data-Types.pdf).

Существуют два типа CRDT [[23]](https://hal.inria.fr/inria-00555588/document): 
* CmRDT - ориентированный на операции (коммутативные RDT, op-based CRDT,  Commmutative RDT), в которых репликация осуществляется атомарным распространением операций модификации. Такие операции должны быть коммутативными для того, чтобы структура данных сходилась к единому состоянию.
* СvRDT - ориентированные на состояния (конвергентные (сходящиеся) RDT, state-based CRDT, Convergent RDT). В которых репликация осуществляется распространением состояния, которые в свою очередь сливаются воедино при помощи операции merge. Существует модификация δ-CRDT, в которых репликация производится слиянием не полного состояния, а лишь измененной части.

Каждая из разновидностей отличается преимуществами и недостатками:
+ CmRDT
	+ **+** низкое потребление траффика при распростанениий операций
	+ **-** требуется атомарный широковещательный способ распространения операций
	+ **-** причинностный порядок распростарнения операций

+ δ-CvRDT
	+ **+** раcпростарнение состояния при помощи алгоритмов распростарнения слухов
	+ **-** дополнительная метаинформация для отслеживания причинно-следственной связи
	+ **-** потребление траффика выше, чем у CmRDT

Основной задачей, стоящей перед δ-CvRDT на данный момент является минимизация возможного траффика. Часть решения этой задачи заключается в уменшении количества повторных пересылок частей данных, что отчасти решается в работе [[24]](http://haslab.uminho.pt/cbm/files/pmldc-2016-join-decomposition.pdf). Другая часть заключается в уменьшении объема непосредственно пересылаемых данных и метаданных.

Несмотря на свою универсальность оба вида CRDT пока плохо подходят для _массовой репликации_, такой, при которой количество реплик составляет порядка сотен тысяч и даже миллионов. В случае δ-CvRDT существенную роль играет метаинформация, отслеживающая причинно - следственные связи, которая как правило и является вариациями version vector, и по потребляемым ресурсам памяти зависит как O(N), где N - количество реплик.

В качестве примера приведем automerge, одну из современных на момент описания это отчета реализаций JSON CRDT. Automerge очень сильно завязана на вектора версий и векторные часы. Документ automerge отслеживает каждое обновление, которое имеет свои логические векторные часы. Простарнственная сложность для документа таким образом будет O(N*U) где N количество реплик, а U количество обновлений документа. Авторами automerge утверждается что деградация начинается уже со ста реплик [29](https://github.com/automerge/automerge/blob/6bed9b0650e9beacdf4ea2996dcea6fb07af55b5/README.md#caveats).

Таким образом нахождение "дешевых" механизмов отслеживания причинно-следственных связей, 
при применений их в качестве метаинформации (кроме других общих случаев их применения) в CRDT позволяет существенно оптимизировать потребляемые ресурсы при синхронизации.

Данная работа ставит целью изучение возможности и способов понизить накладные расходы по памяти при отслеживании причинностных связей при сохранении точности, а также выведения практически применимых схем построения метаинформации. Учитывая известные оценки сложности[11] (подробнее ниже) описывается и анализируется определенный класс моделей.

Исследуя синхронизирующиеся процессы в модели Лэмпорта [[12]](https://amturing.acm.org/p558-lamport.pdf), обнаруживается возможность сведения задачи к рассмотрению некоторого набора параметризированных конфигураций синхронизирующихся процессов. Варьируя параметр, отвечающий за количество процессов выведенны некотроые свойства для N = 3, 4, 5 и 6. 
   
## Краткое описание схемы статьи.

Далее схема стати вяглядит следующим образом

 * **Понятия и определения**. Необходимые понятия, определения и теоремы, требующиеся для вывода основных теоритических и практических результатов. 
 * **Моделирование посетов**. Описана конфигурация изучаемой модели.
 * **Значение размерности. Практические оценки**. Отсылки на результаты в прежних и опутствующих работах.
 * **Вид изучаемых посетов. Приведение к каноническому виду**. Уточнение модели и обоснование
 * **Дополнительне определения**. Введение дополнительных понятий.
 * **Изоморфизм Ψ**. Некоторые свойства модели.
 * **Нахождение посетов размерности 2**. Описание алгоритма поиска.
 * **Результаты поиска**. 
 * **Заключение**.
 * **Продолжение исследований**. 

## Понятия и определения.

Приведем необходимые в дальнейшем понятия, определения и теоремы.

Множество P, c заданным на нем бинарном отношением, обладающее свойствами рефлексивности и транзитивности называется **предпорядком**.

**Частично упорядоченное множество** (ЧУМ, посет (от англ. partially ordered set - poset)): множество P с введенным на нем бинарным отношением ≤, удовлетворяющим аксиомам рефлексивности, антисимметричности и транзитивности. Формально, для любых a, b и c принадлежащим P должно выполнятся.

1. a ≤ a (рефлексивность - каждый элемент сравним сам с собой)
2. если a ≤ b и b ≤ a, то a=b (антисимметричность - два различных элемента не могут быть сравнимы только с одной стороны)
3. если a ≤ b и b ≤ c, тогда a ≤ c(два элемента сравнимы через третий транзитивно)

Далее в статье для краткости используется калька с английского - **посет** (poset) - в качестве альтернативы ЧУМ.
    
Самое отношение ≤ называют отношением частичного порядка.

Для удобства в рамках данной статьи для обозначения частичного порядка будем использовать символ →.

Для любых двух элементов а и b ∈ (P, →), если a→b или b→a, то говорят что а и b сравнимы или упорядочены, иначе a и b несравнимы.

**Линейно (тотально) упорядоченное множество** - это посет, в котором любые два элемента сравнимы.
Такой посет также называют **цепью**. В свою очередь посет, в котором любые два элемента попарно несравнимы называют **антицепью**.

**Линейное расширение** (продолжение) - для посета (P, →) это такой линейний порядок (L, →), для которого выполняется:
    
1. L = P, базовые множества совпадают
2. Если a→b в посете, то a→b в линейном порядке. Линейное расширение сохраняет порядок посета.

**Теорема (_Шпильрайн_)**:
    Для любого посета существет линейное расширение [[13]](https://en.wikipedia.org/wiki/Szpilrajn_extension_theorem).
    
**Ширина посета** - это количество элементов в максимальной антицепи. Формально:
    X ∈ P, где X - антицепь, для любого Y ∈ P, Y - антицепь |X|≥|Y|,
    |X| - и есть ширина посета P.

**Теорема (_Дилворт_)**:
    Минимальное количество цепей, на которое можно разбить посет равно количеству элементов в максимально антицепи [[14]](https://en.wikipedia.org/wiki/Dilworth%27s_theorem).
    
Отсюда второе определение ширины:

Ширина посета - минимальное количество цепей, на которое можно разбить посет.
    
**Высота посета** - количество элементов в наидлиннейшей цепи. Формально
    X ∈ P | X - цепь, для любого Y ∈ P, Y - цепь |X|>=|Y|,
    |X| - есть высота посета.
    
**Реалайзер** - для посета (P, →) набор линейных расширений, пересечение которых дает исходный посет P.

**Размерность посета** (P, →) - это размер минимально возможного реайлазера.

Размерность принято обозначать **dim(P)** [[15]](http://www.jstor.org/stable/2371374)

**Теорема (_Хирагучи_)**:
    Размерность посета P не превосходит его ширины [16].

**Критическая парa** элементов (a, b), это такая упорядоченная пара несравнимых элементов посета P, которые:

* несравнимы
* для любого z ∈ P, из того что b→z, следует что a→z
* для любого z ∈ P, из того что z→a, следует что z→b
    
Следствие: если (a, b) критическая пара, то добавление отношения a→b к P остается частичным порядком, т.е. не нарушает требование транзитивности.

Линейное расширение L **реверсирует** критическую пару (a, b) если для L верно что b→a.

**Утверждение** Набор линейных расширений тогда будет являться реалайзером, когда каждая критическая пара будт обращена хотябы в одном из них.

По поводу вычисления размерности произвольного посета можно сказать следующее:

**Теорема (_Янакаккис_)** Задача определения того, что посет имеет размерность больше 2х является NP-полной [[17]](https://www.researchgate.net/publication/230596220_The_Complexity_of_the_Partial_Order_Dimension_Problem).
Как следствие, для проверки того что посет имеет размерность меньше трех существет полиномиальный алгоритм.

**Гиперграф несравнимых пар H(P)** это такой гиперграф, в котором вершинами явлются несравнимые пары элементов P, а гиперребра строятся на тех множествах S несравнимых пар, для которых выполняется:
    
* Ниодно линейное расширение не реверсирует одновременно все элементы S.
* Если T собственное подмножество S, то существует линейное расширение для P, которое реверсирует все несравнимые пары из T.

Таки образом гиперребрами будут те минимальне наборы несравнимых пар, которые нельзя одновременно обратить в одном линейном расширении.

**Графом несравнимых пар G(P)** будет назваться пограф H(P) с ребрами размера 2.

**Гиперграф несравнимых критических пар H<sub>c</sub>(P)** это подграф H(P), в котором оставлены только вершины - критические пары.

Аналогично **граф несравнимых критических пар G<sub>c</sub>(P)** это подграф G(P), построенный только на критических парах.

**Хроматическое число χ(H)** (гипер)графа H - это минимальное число k, такое что множество вершин графа можно разбить на k непересекающихся классов.

Для (гипер)графов несравнимых и критических пар верны следующие неравенства:

    **dim(P) == χ(H) == χ(H<sub>c</sub>) >= χ(G) == χ(G<sub>c</sub>)**
   
**Теорема (_Фелснер_, _Троттер_)**:
    Если граф G<sub>c</sub>(P) это граф несравнимых критических пар посета P, который не является линейным порядком. Тогда размерность посета P будет равна 2 если, и только если χ(G) == 2 [[18]](https://link.springer.com/article/10.1023/A:1006429830221).

## Моделирование посетов.

В основе лежит классическая асинхронная распределенная система, модель, состоящая из N распределенных процессов P<sub>1</sub> ...P<sub>N</sub>. Процессы не разделяют общие ресуры и сообщаются между собой путем парной передачи сообщений по сети, имеющей произвольную топологию. Коммуникация является асинхронной, с произвольно долгой, но предсказуемой задержкой. Важно что процессы не имеют доступа к глобальным часам и могут использовать только локальные часы.

Понятие времени в таких системах определяется тем, связанны ли события причинно-следственныи связями следующим образом:
    
1. Если два различных события е<sub>1</sub> и е<sub>2</sub> произошли в рамках одного процесса, и е<sub>1</sub> наступило раньше е<sub>2</sub>, то е<sub>1</sub> предшествует е<sub>2</sub>  (е<sub>1</sub> → e<sub>2</sub>).
2. Если е<sub>1</sub> это событие отправки сообщения, а е<sub>2</sub> событие получения, то е<sub>1</sub> предшествует е<sub>2</sub> (е<sub>1</sub> → e<sub>2</sub>).
3. Если е<sub>1</sub>, е<sub>2</sub> и е<sub>3</sub> различные события, (е<sub>1</sub> → e<sub>2</sub>) и (е<sub>2</sub> → e<sub>3</sub>), то е<sub>1</sub> предшествует е<sub>3</sub> (e<sub>1</sub> → e<sub>3</sub>).
    
Таким образом для событий распределенной системы вводится отношение частичного порядка →, которое отражает причинно-следственные связи между ними. События, не связанные между собой отношением предшествования → быдем называть паралелльными e<sub>1</sub> || e<sub>2</sub>. Эту модель ввел Лесли Лэмпорт, под названием произошло до (англ. happens before) [12].

Для определения отношения следования вводятся логичестке часы - всякая функция T(е) (где е - событие), такая что:
для любых е<sub>1</sub> и е<sub>2</sub>, e<sub>1</sub> → e<sub>2</sub> тогда и только тогда, когда T(e<sub>1</sub>)<T(e<sub>2</sub>).

Наиболее распростаненной реализацией механизма логических часов являетютя векторные часы [мартин][фридж] представляют из себя вектор целых чисел, по одному на каждый процесс продвижение и сравнение которых проедставляют из себя следующие процедуры:
    
* При наступлении события e в процессе P<sub>i</sub>, i-компонента увеличивается на 1
* При отсылке сообщения из процесса P<sub>i</sub>, i-компонента увеличивается на 1
* При принятии сообщения процессом P<sub>j</sub>, j-компонента увеличивается на 1
    
Векторные часы V<sub>1</sub><V<sub>2</sub> тогда и только тогда, когда каждый компонент V<sub>2</sub> больше или равен соответсвующему компоненту V<sub>1</sub>.

В случае, когда события в процессах представляют из себя изменения и согласование данных, картина несколько изменяется. Передача сообщений имеет смысл синхронизации, потому данные, соответсвующие событиям отправки и получения должны быть одинаковы (прично-следственно эквивалентны). Типичная реализация отслеживания отношений между данными представляет вектор версий [[19]] (https://en.wikipedia.org/wiki/Version_vector) - аналог векторных часов, но в отличии от них _при посыке или получении сообщений компоненты вектора не инкрементируются_, а берется максимум для каждой пары соответсвующих компонент, что естественным образом отражает действие по согласованию данных.

## Значение размерности. Практические оценки.

Оценка сверху на размер векторных часов описана в [11]. По своей сути векторыне часы есть реализация способа натягивания посета на целочисленое векторное пространство размерности d. Минимально возможная размерность векторного пространства, на которое можно натянуть данный посет и является  смыслом оригинального определения размерности [[15]](http://www.jstor.org/stable/2371374).
И это же минимально возможное значение размерности может быть гораздо меньше его ширины, из чего можно сделать вывод о возможности нахождения логических часов и version vector подобных структур, размер которых меньше чем количество процессов.

Эмпирические исследования по анализу размерностей посетов, образующихся реальными распределенными системами показывают, что в действительности размерности таких посетов на порядки меньше максимально возможного значения. В частности стандарный пример посета "корона" S(0, n), имеющий размерность n, если рассматривать его в контексте взаимодействующих процессов, являет собой атомарную широковещательную рассылку сообщений и, одновременный же, широковещательный прием этих сообщений. Появление такой фигуры крайне необычно на практике, хотя формально не нарушает приведенную модель.

В работе [[20]](https://ieeexplore.ieee.org/document/797397/) дана приближенная оценка реального значения размерности большого числа распределенных систем, на основании которых можно заключить что в действительности размерность посетов гораздо меньше теоретической оценки. Например для 1500+ процессов размерность была 10. В дальнейшем авторами были предприняты попыки [[21]](https://pdfs.semanticscholar.org/b4ed/53e58111737a6f4dfee98c15385c8b4aa1cf.pdf) [[22]](https://pdfs.semanticscholar.org/d0c2/401ea2440f983c878414414d55f0130f8197.pdf) генерации часов на основе жадного построения реалайзера, размер которого гораздо меньше векторных часов/векторв версий, которые могли бы быть применены. К сожалению, работа не была доведена до логического конца, а кроме того такой подход требовал глобального видения (в отличии от векторов версий).

Из подобных исследований можно сделать вывод что причинностные связи в реальных распределенных системах могут отслеживаться струкурами данных, занимающих гораздо меньше места, чем размерность образуемого посета. 

Авторы статьи пошли немного другим путем: 

1. Предполагая что определенные фигуры в образуемых посетах либо не могут появиться на практике, либо могут быть искусственно удалены.
2. Предприняв сокращение посетов и перебрав для фиксированного количества процессов все возможные конфигурации выяснить, каким образом процессам необходимо синхронизироваться, чтобы результирующий посет оставался размерности 2.
3. Исследовав полученные конфигурации, вывести правила и закономерности, следуя которым, синхронизирющиеся процессы будут всегда образовывать посет размерности 2.
4. Использовав такие правила вывести строгие точные логические часы потребляющие O(1) памяти.
    
## Вид изучаемых посетов. Приведение к каноническому виду.

Опишем преобразования и сведение посетов к каноническому виду.

Преобразование A:
Существует один тонкий момент при моделировании системы, где процессы модифицируют и согласуют данные. На практике посыл/получение происходит в несколько этапов: 
    
1. процесс инициирующий согласование отсылает данные, 
2. парный процесс эти данные получает и синхронизирует локальную копию с присланной
3. в свою очередь парный процесс отсылает собственные данные для сверки
4. инициирующий процесс получает и синхронизирует данные.

Для простоты, можно зафиксировать требование того, что между последовательной отправкой/получением для инициирующго процесса (и получением/отправкой для парного к нему процесса) не происходит локальных изменений данных . Диаграмма выполнеия таких процессов будет выглядить следующим образом ("квадрат синхронизации"): [рисунок изменить поставить точки и стрелки](https://pp.userapi.com/c846320/v846320295/40822/rJ_8zUG4IMA.jpg)
Такой квадрат синхронизации можно стянуть в 2 синхронизированные точки, получая классическую форму синхронизирующихся процессов [рисунок изменить соответственно](https://pp.userapi.com/c830209/v830209295/ed871/WGPuJA4PVu8.jpg)

Однако такая форма уже не будет являться посетом, а будет образовывать _предпорядок_. Для того чтобы обратно получить посет, заменим синхронизирующее друнаправленное ребро на точку, а исходящие/входящие точки раздвоим, и проведем ребра в соответсвии с семантикой: [рисунок](https://pp.userapi.com/c831508/v831508295/eded1/C-5lC8avr7U.jpg).

Таким образом преобразование А будет заключатся в замене квадрата синхронизации на join/fork фигуру [рисунок](https://pp.userapi.com/c846217/v846217295/3db5d/bFMcN4UVlfA.jpg). Далее на рисунках под ребром <--->, будет пониматься именно такая join/fork фигура.

Преобразование B:
Рассмотрев 4 различных случая возможного появления критических пар между синхронизирующимися процессами ([рисунок](https://sun1-4.userapi.com/c840520/v840520295/7c3b6/ekQnVcQebIU.jpg)), можно заметить следующее: 2 процесса между синхронизациями образуют не более 2х критических пар. Самый общий случай из них показан на рисунке [рисунок](https://pp.userapi.com/c845421/v845421295/40f68/eVxtsHXcs08.jpg). 

Используя данные замечания для анализа критических пар достаточно между синхронизациями производить только по одной локальной модифкации (т.е. добавляется одна точка). Критические пары будут образовываться на этих точках()[рисунок]

Положение критических пар при преобразовании А является инвариантным, т.к. оно не изменяет отношения порядка для точек, лежащих между синхронизациями. Начальные точки критических пар находятся в точках завершающих синхронизацию, а конечные - в точках синхронизацию начинающих (рисунок)[рисунок]. Это можно проверить заметив что, во первых, критические пары не могут иметь начальную точку до синхронизации, а конечную после. Во вторых что между синхронизациями все точки не находтся в отношении предшествования, а значит возможные начальными и конечными точками критических пар могут быть только те, что лежат непосредственно после и перед синхронизацией.

Изучаемые посеты будут иметь только фиксированное количество процессов. Примеры [рисунок](https://pp.userapi.com/c845417/v845417295/43044/UiPzahUa66A.jpg) [рисунок](https://pp.userapi.com/c846420/v846420295/3e0af/HyyBzJ3yiwk.jpg) [рисунок](https://pp.userapi.com/c846523/v846523295/3e1a3/n-ikwg42HSc.jpg)

Это и буду исследуемые нами посеты.

## Дополнительне определения

**Фронтир** - это такое множество F точек посета P, которые образуется при выполнении синхронизирующихся процессов, которые могут _существовать в этом выполнении одновременно_. В нашей модели, любые две точки, соединенные связанным направленным путем не могут принадлежать одному фронтиру. Нетрудно также догадаться, что размер фронтира будет равен количеству процессов.
Схожее понятие было введено в [8].

Рассмотрим два фронтира F<sub>1</sub> и F<sub>2</sub>. В случае если, каждый элемент F<sub>1</sub> предшевствует каждому из F<sub>2</sub>, будем говорить что F<sub>1</sub> предшевствует или _полностью синхронизирован_ с F<sub>2</sub>. Если два фронтира F<sub>1</sub> и F<sub>2</sub> полностью синхронизированны друг с другом, то посет заключенный между F<sub>1</sub> и F<sub>2</sub> будем назвать **Полностью Синхронизированным Исполнением (ПСИ)**. Обозначим его **Ψ(N, S)**, где N это количество процессов, S - количество синхронизаций.
**[рисунок и объяснение на его примере!]()**

Если при этом не найдется отличного от них F<sub>1</sub> и F<sub>2</sub> фронтира F<sub>3</sub>, котороый не был бы синхронизирован с одним, но был бы синхронизирован с другим, то посет заключенный между F<sub>1</sub> и F<sub>2</sub> будем назвать **Минимальным Полностью Синхронизированным Исполнением (мПСИ)** и обозначать **mΨ(N, S)**. Примеры mΨ(3, 3) с выделенными фронтирами на [рисунке](https://pp.userapi.com/c846321/v846321295/3d0a1/uhkwMLUBqJg.jpg) и [рисунке](https://pp.userapi.com/c845219/v845219295/414dc/IN1HJ23jiFw.jpg).

Для фиксированного количества процессов N в начальном состоянии, минимальное количество синхронизаций, которое необхоимо провести, чтобы получить mΨ(N, S) вычисляется по формуле:

count(N) == N, если N четно
count(N) == N+1, если N нечетно

#### (Де)Композиция ПСИ (Ψ-(де)композиция).
Если взять два или более mΨ(N, S), и последовательно соединяя соответственно начальные и конецные точки (т.е. отождествляя последний и первый фронтиры) получим последовательную Ψ-композицию. Нетрудно убедится, что при такой операции внутри посета будут образовываться Ψ, отличные от образующих, и лежащих в пределах их начального и конечного фронтиров. 

Операция декомпозиции состоит в том, что от данного посета последовательно отделяются mΨ. Полученная при этом последовательность mΨ, опять же, может быть не уникальной.

Размерностью dim(Ψ), будет размерность соответсвующего ей посета.

Таким образом _размерностью посета_ будет _максимальная размерность Ψ_ среди всех возможных Ψ-декомпозициях для него.

## Изоморфизм Ψ.

#### Базовый изоморфизм.
Рассматриваемые Ψ-посеты изоморфны с точностью до перестановок процессов.

Два различных Ψ<sub>1</sub>(N, S) и Ψ<sub>2</sub>(N, S) будут изоморфными, если существует такая перестановка _p_ номеров N процессов, что при применнении её к Ψ<sub>1</sub> получим Ψ<sub>2</sub>.

Процесс определения изоморфности двух Ψ достаточно прост: нужно перебрать все перестановки и последовательно сравнить синхронизации. Однако данный процесс является непрактичным, потому далее будем использовать другой способ определения изоморфизма.

Пример двух пар изоморфных mΨ приведен на [рисунок] (рисунок) [рисунок] (рисунок).

#### Изоморфизм по синхронизациям.
Для каждого процесса по мере работы системы ведется имя: в начале оно пустое, а при каждой синхронизации к нему добавляется глобальный номер этой синхронизации. Такое имя однозначно определяет положение процесса во всем исполнении (исключая тривиальные случаи). Если сравнить множестово имен процессов для двух Ψ, то окажется что если они эквиваленты, то эти Ψ равны.

Взяв полиномиальных хэш от отсортированных имен процессов получим хэш для Ψ.
    
## Нахождение Ψ размерности 2.

Опишем процесс нахождения Ψ размерности 2.

#### Базовая процедура

* Зафиксируем количество процессов N, и положим что в каждом процессе произошло по одному событию. Это будет начальной конфигурацией.
* Запустим backtrack процедуру, которая на каждом шаге перебирает все пары процессов, синхронизирует эту пару и рекурсивно запускает себя дальше.
* Критерием останова будет достижение определенного наперед заданного количества синхронизаций. При его достижении происходит проверка, будет ли иметь полученный посет размерность 2.

Некоторые оптимизации позволяют резко сократить перебор и сильно увеличить скорость поиска:
* Проверять получающийся посет можно на каждом шаге перебора, тем самым отсечь заведомо неподходящие посеты.
* Количество изоморфных посетов с увеличеним N растет как Θ(N!). Использовав кэш в виде хэш-таблицы и хэшируя получающиеся посеты, можно добиться огромного отсечения при переборе. При этом, однако резко увеличивается потребление памяти.
* Процедура легко параллелится при помощи техник fork/join паралеллизма с котролем ветвления.

Процессы в Ψ<sub>i</sub>(N, S) занумерованны от 0 до N-1. В backtrack процедуре пары процессов для синхронизации генирируются в лексикографичестком порядке, например <0,1>, <0,2>, ..., <0,N>,<1,0>, ... ,<1,N>, ..., ..., <N-1, N>. Этот порядок порождает и лексикографический порядок для генирируемых Ψ. Потому имеет место запись Ψ<sub>i</sub>(N, S)#K, где K порядковый номер Ψ среди всех Ψ(N, S). Пример нескольких упорядоченных Ψ приведен на рисунке [рисунок](рисунок).

#### Проверка на размерность 2

Как уже было сказанно, для определения того, что посет имеет размерность 2 существует полиномиальный алгоритм. Наивная реализация имеет временную сложность O(N<sup>5</sup>) где N это количестов событий в исполнении, и состоит из следующих шагов:

##### Шаг 1. Нахождение всех критических пар
* На основе данного посета строится ориентированный граф с вершинами - точками посета, и ориентированными ребрами между парами вершин, непосредственно находящимися в отношении следования.
* С помощью алгоритма Флойда нахождения кратчайших путей между всеми парами вершин полученный граф достраивается до графа достижимости для данного посета.
* Перебираются все пары вершин графа достижимости, и используя следствие из определения критической пары, проверяется, образуют ли они критическую пару.

##### Шаг 2. Генерация графа несравнимых критических пар
* Две критические пары не могут лежать в одном линейном расширении если при их обращении в посет перестанет быть посетом. Это возможно только в том случае если при обращении образуется ориентированный цикл в графе достижимости. Используя этот признак,  перебирая все критические пары строится граф несравнимых критических пар.

##### Шаг 3. Проверка полученного графа на двудольность.
* Двудольность графа проверяется поиском в глубину и попутным разбиением вершин на 2 класса. Если в процессе поиска вершину необходимо отнести сразу к двум классам граф считается недвудольным. Запуски генерации показали, что практической необходимости в распараллеливании или какой либо оптимизации нет, т.к. основной объем времени занимает непосредственно перебор.

## Результаты поиска

Осуществив проверку и генерацию Ψ с количеством процессов от 2 до 7 предложим некоторую классификацию полученных фигур.

По возможности построения путем композиции можно разделить на:

 * **Общие** - фигуры, которые сохраняют размерность 2 при Ψ-композиции как сами с собой, так и между друг другом.
 * **Частные** - все остальные, т.е. те что нарушают свойство размерности при Ψ-композиции.

По своей структуре Ψ можно разделить на:
 * **Регулярные** - фигуры, в которых четко просматривается структура и алгоритм, по которому выбираются пары для синхронизации.
 * **Хаотичные** - неструктурированные фигуры, для которых нет возможности умозрительно определить алгоритм синхронизаций.
 * **Полурегулярные** - неструктурированные, для которых однако можно определенным образом построить Ψ-композиции.

Кроме машинного перебора всех возможных фигур Ψ(N, S) ввиду практической возможности и простоты осуществлялся также ручной анализ Ψ(3, X). Тривиальный случай Ψ(2, X) рассматривать не будем - два процесса всегда образуют посет размерности 2.

##### Ψ(3, S)
Три процесса полностью синхронизируются при помощи 3х синхронизаций и образуют ровно две различных фигуры, изображенных на рисунке [рисунок](). Первая фигура является случаем плоской сетки, описанной ниже. Кроме машинной проверки оба случая были проверенны вручную построением риалайзера. Композиция этих фигур также всегда будет размерности 2. Обе фигуры можно отнести к регулярным и общим.

##### Ψ(4, S)
Для четырех процессов требуется минимум 5 синхронизаций, чтобы образовывать посет размера 2: mΨ(4, 5). Образуются 10 различных фигур [рисунки](), причем 2 из них (#9 и #10) содержат _параллельные синхронизации_, т.е. синхронизации, точки которых не состоят в отношении следования, и могут выполнятся в любом порядке друг относительно друга. 
**(детальное описание всех)**
Некотрые mΨ(4, 5) можно соединить вместе при помощи последовательной Ψ композиции. 
* Пример1. Соединяя последовательно mΨ(4, 5)#1 сам с собой образуется также посет размерности 2 [рисунок]().
* Пример2. Соединяя последовательно mΨ(4, 5)#1 и mΨ(4, 5)#4, а также mΨ(4, 5)#4 и mΨ(4, 5)#1 оразуется посет размерности 2 [рисунок]().
В таблице приведены все найденные пары mΨ(4, 5), для которых после применения Ψ-композиции образуется посет размерности 2.

|mΨ(4, 5)#x|mΨ(4, 5)#y
|-|-------------
|1|1, 4, 9
|4|1, 4, 9 
|6|9
|9|1, 4, 9
* Пример3. Исходя из таблицы, схему можно строить, например, так: (mΨ(4, 5)#4; mΨ(4, 5)#9; mΨ(4, 5)#1; ...) и при этом получать посет, размера 2.

Таким образом, если использовать схемы синхронизации **_4х_** процессов, построенные Ψ-композицией последовательно, следуя таблице, будет достаточно **_2х_** целых чисех для отслеживания причинно-следственной связи.
**(перестановки mΨ(4, 5)#8)**

##### Ψ(5, S)
Пять процессов синхронизируются, образовывая посет размера 2, минимум за 7 синхронизаций: mΨ(5, 7). Всего для 5 процессов обнаружено 40 Ψ(5, 7), 8 из которых имеют параллельные синхронизации.
Некоторые из них изображены на [рисунке](https://pp.userapi.com/c639831/v639831173/612ff/JtegbaNYMjQ.jpg).

##### Ψ(6, S)
Шесть процессов синхронизируются, образовывая посет размера 2, за 9 синхронизаций: mΨ(6, 9).
Всего для 6 процессов обнаружено 180 mΨ(6, 9).

Последовательность A(N) количества mΨ(N, S) [1, 2, 10, 40, 180] является началом последовательности [A151024](https://oeis.org/A151024) в OEIS[25].

Для конфигураций с количеством процессов 5 и 6 возможно применить Ψ-композицию для различных mΨ, и для их перестановок, однако такой подход к анализу не является системным и потому кроме как для 4х процессов более не применялся.

#### Обобщенные паттерны
Опишем найденные регулярные паттерны взаимодействия N процессов, при которых гарантированно образуется посеты размерности 2.

##### Плоская сетка 
Простейший случай, когда все процессы находятся в линейном порядке (определяемом ID - идентификатором процессов). Если каждому процессу P с идентификатором ID<sub>p</sub>, позволено синхронизироваться только с двумя соседними процессами P<sub>1</sub> и P<sub>2</sub>, с идентификаторами ID<sub>P<sub>1</sub></sub> и ID<sub>P<sub>2</sub></sub>, такими что не найдется процесса P<sub>X</sub> с идентификатором ID<sub>p<sub>x</sub></sub> и ID<sub>P<sub>1</sub></sub> < ID<sub>P<sub>X</sub></sub> < ID<sub>P</sub></sub>, либо ID<sub>P</sub> < ID<sub>P<sub>X</sub></sub> < ID<sub>P<sub>2</sub></sub>. Другими словами синхронизироваться можно только с двумя непосредственными соседями [рисунок](). 

Такой паттерн назовем _"плоская сетка"_. Следует заметить, что синхронизация может происходить в любой момент, в не зависимости от каких-либо других синхронизаций. Топология сети, образуемая связями процессов образует обыкновенную цепь [рисунок]().
Частными случаями будут mΨ(3,3)#1, mΨ(4, 5)#, mΨ(6, 7)# [ссылка на рисунок]().

#####  Gather-Scatter
"Собрал-раздал" (или meet-in-the-middle). Аналогично с плоской сеткой, процессы линейно упорядоченны. Синхронизация происходит раундами. Все события призошедшие до начала раунда синхронизируются во всех процессах к окончанию раунда. 
* В рамках первой половины  раунда выделяется один _центральный_ процесс, 2 самых дальних процесса синхронизируются с ближайшими, эти два в свою очередь, с ещё более ближайшими к центральному, и так далее пока не дойдет до центрального. В результате на центральном процессе соберутся все изменения, доступные к началу раунда. 
* Во второй половине раунда синхронизация проводятся в обратном порядке, от ближних к дальним, распростроняя собранные изменения назад [рисунок](). 

Стоит отметить что порядок не обязательно должен задаваться именно идентификаторами и быть всегда фиксированный. Главное, чтобы образовывался вышеописанный паттерн. Выбор ценрального также может определяться по ходу раунда.
    
##### Лесенка
**Один синхронизирует всех?**

#### Другие регулярные паттерны

##### Gather-scatter inside-out
Или собрал-раздал наизнанку. Первый этап аналогичен Gather-Scatter - происходит последовательный сбор изменений с крайних процессов к центральному. Однако после того, как все изменения собраны на центральном процессе происходит следующее: выделим процесс, который синхронизировался с центральным в последнюю очередь, на этом процессе также будут собраны все изменения. Теперь эти 2 процесса (центральный и только что выделенный парный) будут синхронизироваться со всеми остальными, таким образом, что тот, что имеет меньший ID, будет синхронизироваться с теми, что имеют строго больший, и наоборот. Подробнее с этой схемой можно ознакомится на [рисунок](https://pp.userapi.com/c847019/v847019339/1907f/U6rTeVNrbQQ.jpg) [рисунок](https://pp.userapi.com/c830709/v830709339/bcbb4/jorzdyyTCZI.jpg).

К сожалению, Ψ-композиция такой фигуры работает только для 4х процессов (это Ψ(4, 5)#10), для 5ти процессов же уже не работает.

## Заключение. 
Основными текущими результатами исследования выделяются:
* Описание частного случая модели синхронизирующихся процессов, вместе с выделенными сущностями Ψ и mΨ.
* Описание алгоритма проверки посета на размерность равную двум. Алгоритм является модульным и при замене шага 3 на более общий - минимальную раскраску гиперграфа - может служить алгоритмом нахождения размерности любого посета.
* Нахождние некоторых общих, частных и регулярных mΨ, применение которых начиная с количества процессов больших 4м уже **снижает накладные расходы в разы**, в противовес существующим подходам.
* Демонстрация того факта, что три процесса при синхронизациях всегда образуют посет размерности 2.
* Приведение нескольких общих паттернов синхронизции, образующих посет размерности 2, для N процессов.

Из недостатков среди результатов хотелось бы подчеркнуть:
* Отсутствие готовых алгоритмов синхронизаций для приведенных Ψ и общих паттернов
* В случае общих паттернов сеть, образуемая синхронизациями формируют весьма непрактичную топологию в виде цепи.
* Низкая скорость распростанения обновлений (далее тик синхронизаций это дискретный отрезок времени, в течении которого происходят независимые друг от друга, т.е. параллельные синхронизации)
	+ в случае сетки и лесенки требуется N-1 тик синхронизаций.
	+ в случае Gather-Scatter N/2 тиков синхронизаций.

## Продолжение исследований
Дальнейшие изыскания будут проводится по двум направлениям. 

Первое состоит в составлении конкретных алгоритмов синхронизации, действующих локально, таких что результирующий посет будет образовывать общие паттерны, либо частные регулярные фигуры. 

Второе, более обширное, заключается в анализе образующихся при синхронизациях посетов большей размерности. При этом будет осуществятся аналогичный умозрительный анализ полученных фигур, выявление паттернов и попытка построения алгоритмов отслеживания причинности. Это напавление требует использование больших вычислительных мощностей.
    
## Список ссылок и литературы

 1.  _Brewer, Eric A._  [A Certain Freedom: Thoughts on the CAP Theorem](http://portal.acm.org/ft_gateway.cfm?id=1835701&type=pdf&CFID=25475815)  (англ.) // Proceeding of the XXIX ACM SIGACT-SIGOPS symposium on Principles of distributed computing. — N. Y.: [ACM](https://ru.wikipedia.org/wiki/ACM "ACM"), 2010. — Iss. 29. — No. 1. — P. 335—336.
 2. [Vogels, W.](https://en.wikipedia.org/wiki/Werner_Vogels "Werner Vogels")  (2009). "Eventually consistent".  _Communications of the ACM_.  **52**: 40.  [doi](https://en.wikipedia.org/wiki/Digital_object_identifier "Digital object identifier"):[10.1145/1435417.1435432](https://doi.org/10.1145%2F1435417.1435432).
 3. Saito, Yasushi; Shapiro, Marc (2005). "Optimistic replication". _[ACM Computing Surveys](https://en.wikipedia.org/wiki/ACM_Computing_Surveys "ACM Computing Surveys")_. **37** (1): 42–81. [doi](https://en.wikipedia.org/wiki/Digital_object_identifier "Digital object identifier"):[10.1145/1057977.1057980](https://doi.org/10.1145%2F1057977.1057980).
 4. Mattern, Friedman. (October 1988), "Virtual Time and Global States of Distributed Systems", in Cosnard, M., _Proc. Workshop on Parallel and Distributed Algorithms_, Chateau de Bonas, France: Elsevier, pp. 215–226
 5. Colin J. Fidge (February 1988). ["Timestamps in Message-Passing Systems That Preserve the Partial Ordering"](http://zoo.cs.yale.edu/classes/cs426/2012/lab/bib/fidge88timestamps.pdf)  (PDF). In K. Raymond (Ed.). _Proc. of the 11th Australian Computer Science Conference (ACSC'88)
 6. Nuno Preguiça, Carlos Baquero, Paulo Almeida, Victor Fonte and Ricardo Gonçalves. Brief Announcement: Efficient Causality Tracking in Distributed Storage Systems With Dotted Version Vectors. ACM PODC, pp. 335-336, 2012.
 7. ByungHoon Kang, Robert Wilensky, and John Kubiatowicz. The Hash History Approach for Reconciling Mutual Inconsistency. ICDCS, pp. 670-677, IEEE Computer Society, 2003.
 8. Paulo Almeida, Carlos Baquero and Victor Fonte. Version Stamps: Decentralized Version Vectors. ICDCS, pp. 544-551, 2002.
 9. https://haslab.wordpress.com/2011/07/08/version-vectors-are-not-vector-clocks/
 10. Lee, Conrad,  Nick, Bobo,  Brandes, Ulrik,  Cunningham, Pádraig : Link Prediction with Social Vector Clocks. In: Proceedings of the 19th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2013-08-14.
 11. Bernadette Charron-Bost. Concerning the size of logical clocks in distributed systems. Journal Information Processing Letters, Volume 39, Issue 1, July 12, 1991, Pages 11-16.
 12. Leslie Lamport . Time, clocks, and the ordering of events in a distributed system. Comm. ACM 21, 7 (July 1978), 558 - 565.
 13. Szpilrajn, E. (1930), ["Sur l'extension de l'ordre partiel"](http://matwbn.icm.edu.pl/tresc.php?wyd=1&tom=16), _[Fundamenta Mathematicae](https://en.wikipedia.org/wiki/Fundamenta_Mathematicae "Fundamenta Mathematicae")_, **16**: 386–389
 14. [Dilworth, Robert P.](https://en.wikipedia.org/wiki/Robert_P._Dilworth "Robert P. Dilworth") (1950), "A Decomposition Theorem for Partially Ordered Sets", _[Annals of Mathematics](https://en.wikipedia.org/wiki/Annals_of_Mathematics "Annals of Mathematics")_, **51** (1): 161–166
 15. Dushnik, Ben & Miller, E. W. (1941), "[Partially Ordered Sets](https://www.jstor.org/stable/2371374)", _[American Journal of Mathematics](https://ru.wikipedia.org/wiki/American_Journal_of_Mathematics "American Journal of Mathematics")_ Т. 63 (3): 600-610
 16. Tosio Hiragushi, On the dimension of orders, Tech. Rept., University of Kanazawa, 1955.
 17. Mihalis Yannakakis, The Complexity of the Partial Order Dimension Problem, [SIAM Journal on Algebraic and Discrete Methods](https://www.researchgate.net/journal/0196-5212_SIAM_Journal_on_Algebraic_and_Discrete_Methods)3(3):351-358 · September 1982
 18. Stefan Felsner, William T. Trotter. Dimension, Graph and Hypergraph Coloring. June 2000, Volume  17, pp 167–177
 19. Douglas Parker, Gerald Popek, Gerard Rudisin, Allen Stoughton, Bruce Walker, Evelyn Walton, Johanna Chow, David Edwards, Stephen Kiser, and [Charles Kline](https://en.wikipedia.org/w/index.php?title=Charles_S._Kline&action=edit&redlink=1 "Charles S. Kline (page does not exist)"). Detection of mutual inconsistency in distributed systems. Transactions on Software Engineering. 1983
 20. P.A.S. Ward. # An offline algorithm for dimension-bound analysis. Parallel Processing, 1999. Proceedings. 1999 International Conference on. 24-24 Sept. 1999
 21. Paul A. S. Ward. A framework algorithm for dynamic, centralized dimension-bounded timestamps. Proceeding CASCON '00 Proceedings of the 2000 conference of the Centre for Advanced Studies on Collaborative research Page 14
 22. Paul A.S. Ward, David J. Taylor. A Hierarchical Cluster Algorithm for Dynamic, Centralized Timestamps. Proceeding ICDCS '01 Proceedings of the The 21st International Conference on Distributed Computing Systems, Page 585. 
 23. Shapiro, Marc; Preguiça, Nuno; Baquero, Carlos; Zawirski, Marek (13 January 2011). "A Comprehensive Study of Convergent and Commutative Replicated Data Types". _RR-7506_. HAL - Inria.
 24. Vitor Enes, Carlos Baquero, Paulo Sérgio Almeida, Ali Shoker. Join Decompositions for Efficient Synchronization of CRDTs after a Network Partition: Work in progress report. Proceeding [PMLDC '16](http://2016.ecoop.org/track/PMLDC-2016 "Conference Website")  First Workshop on Programming Models and Languages for Distributed Computing, Article No. 6.
 25. On-Line Encyclopedia of Integer Sequences, A151024. https://oeis.org/A151024
 26. Giuseppe DeCandia, Deniz Hastorun, Madan Jampani, Gunavardhan Kakulapati, Avinash Lakshman, Alex Pilchin, Swaminathan Sivasubramanian, Peter Vosshall, and Werner Vogels. Dynamo: Amazon’s highly available key-value store. In Symp. on Op. Sys. Principles (SOSP), volume 41 of Operating Systems Review, pages 205–220, Stevenson, Washington, USA, October 2007. ACM
 27. Cihan Biyikoglu, Under the Hood: Redis CRDTs, WHITE PAPER, RedisLabs.
 28. https://docs.microsoft.com/en-us/azure/cosmos-db/multi-region-writers
 29. https://github.com/automerge/automerge/blob/6bed9b0650e9beacdf4ea2996dcea6fb07af55b5/README.md#caveats